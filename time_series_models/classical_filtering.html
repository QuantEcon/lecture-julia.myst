
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>59. Classical Filtering With Linear Algebra &#8212; Quantitative Economics with Julia</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/quantecon-book-theme.9deb0a26de8466f54124a1959c24cd33.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">


    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="../_static/quantecon-book-theme.43eb86aa48ec3aed660cb313c38068cd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://julia.quantecon.org/time_series_models/classical_filtering.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="60. Dynamic Stackelberg Problems" href="../dynamic_programming_squared/dyn_stack.html" />
    <link rel="prev" title="58. Classical Control with Linear Algebra" href="lu_tricks.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Jesse Perla &amp; Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Julia, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on quantitative economic modeling, designed and written by Jesse Perla, Thomas J. Sargent and John Stachurski. The language instruction is Julia. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Classical Filtering With Linear Algebra"/>
<meta name="twitter:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Jesse Perla, Thomas J. Sargent and John Stachurski. The language instruction is Julia.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Classical Filtering With Linear Algebra" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://julia.quantecon.org/time_series_models/classical_filtering.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Jesse Perla, Thomas J. Sargent and John Stachurski. The language instruction is Julia." />
<meta property="og:site_name" content="Quantitative Economics with Julia" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="wrapper">

        <div class="main">

            <div class="page" id=time_series_models/classical_filtering>

                <div class="page__toc">

                    <div class="inner">

                        
                        <div class="page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   59.1. Overview
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     59.1.1. References
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#infinite-horizon-prediction-and-filtering-problems">
   59.2. Infinite Horizon Prediction and Filtering Problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem-formulation">
     59.2.1. Problem formulation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finite-dimensional-prediction">
   59.3. Finite Dimensional Prediction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementation">
     59.3.1. Implementation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-1">
     59.3.2. Example 1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-2">
     59.3.3. Example 2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prediction">
     59.3.4. Prediction
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#combined-finite-dimensional-control-and-prediction">
   59.4. Combined Finite Dimensional Control and Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   59.5. Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1">
     59.5.1. Exercise 1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2">
     59.5.2. Exercise 2
    </a>
   </li>
  </ul>
 </li>
</ul>

                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="../_static/qe-logo-large.png" class="logo" alt="logo"></a>
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="page__header">

                    <div class="page__header-copy">

                        <p class="page__header-heading"><a href="intro.html">Quantitative Economics with Julia</a></p>

                        <p class="page__header-subheading">Classical Filtering With Linear Algebra</p>

                    </div>

                    <p class="page__header-authors">Jesse Perla & Thomas J. Sargent & John Stachurski</p>

                </div> <!-- .page__header -->



                
                <main class="page__content" role="main">
                    
                    <div>
                        
  <div id="qe-notebook-header" style="text-align:right;">
        <a href="https://quantecon.org/" title="quantecon.org">
                <img style="width:250px;display:inline;" src="https://assets.quantecon.org/img/qe-menubar-logo.svg" alt="QuantEcon">
        </a>
</div><div class="section" id="classical-filtering-with-linear-algebra">
<h1><a class="toc-backref" href="#id18"><span class="section-number">59. </span>Classical Filtering With Linear Algebra</a><a class="headerlink" href="#classical-filtering-with-linear-algebra" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#classical-filtering-with-linear-algebra" id="id18">Classical Filtering With Linear Algebra</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id19">Overview</a></p></li>
<li><p><a class="reference internal" href="#infinite-horizon-prediction-and-filtering-problems" id="id20">Infinite Horizon Prediction and Filtering Problems</a></p></li>
<li><p><a class="reference internal" href="#finite-dimensional-prediction" id="id21">Finite Dimensional Prediction</a></p></li>
<li><p><a class="reference internal" href="#combined-finite-dimensional-control-and-prediction" id="id22">Combined Finite Dimensional Control and Prediction</a></p></li>
<li><p><a class="reference internal" href="#exercises" id="id23">Exercises</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id19"><span class="section-number">59.1. </span>Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This is a sequel to the earlier lecture <a class="reference internal" href="#"><span class="doc">Classical Control with Linear Algebra</span></a>.</p>
<p>That lecture used linear algebra – in particular,  the <a class="reference external" href="https://en.wikipedia.org/wiki/LU_decomposition">LU decomposition</a>  – to formulate and solve a class of linear-quadratic optimal control problems.</p>
<p>In this lecture, we’ll be using a closely related decomposition, the <a class="reference external" href="https://en.wikipedia.org/wiki/Cholesky_decomposition">Cholesky decomposition</a> , to solve linear prediction and filtering problems.</p>
<p>We exploit the useful fact that there is an intimate connection between two superficially different classes of problems:</p>
<ul class="simple">
<li><p>deterministic linear-quadratic (LQ) optimal control problems</p></li>
<li><p>linear least squares prediction and filtering problems</p></li>
</ul>
<p>The first class of problems involves no randomness, while the second is all about randomness.</p>
<p>Nevertheless,  essentially the same mathematics  solves both type of problem.</p>
<p>This connection, which is often termed “duality,” is present whether one uses “classical” or “recursive” solution procedures.</p>
<p>In fact we saw duality at work earlier when we formulated control and prediction problems recursively in lectures <a class="reference internal" href="../dynamic_programming/lqcontrol.html"><span class="doc">LQ dynamic programming problems</span></a>, <a class="reference internal" href="../tools_and_techniques/kalman.html"><span class="doc">A first look at the Kalman filter</span></a>, and <a class="reference internal" href="../dynamic_programming/perm_income.html"><span class="doc">The permanent income model</span></a>.</p>
<p>A useful consequence of duality is that</p>
<ul class="simple">
<li><p>With every LQ control problem there is implicitly affiliated a linear least squares prediction or filtering problem.</p></li>
<li><p>With every linear least squares prediction or filtering problem there is implicitly affiliated a LQ control problem.</p></li>
</ul>
<p>An understanding of these connections has repeatedly proved useful in cracking interesting applied problems.</p>
<p>For example, Sargent <span id="id1">[<a class="reference internal" href="../zreferences.html#id123">Sar87</a>]</span> [chs. IX, XIV] and Hansen and Sargent <span id="id2">[<a class="reference internal" href="../zreferences.html#id35">HS80</a>]</span> formulated and solved control and filtering problems using <span class="math notranslate nohighlight">\(z\)</span>-transform methods.</p>
<p>In this lecture we investigate these ideas using mostly elementary linear algebra.</p>
<div class="section" id="references">
<h3><span class="section-number">59.1.1. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<p>Useful references include <span id="id3">[<a class="reference internal" href="../zreferences.html#id34">Whi63</a>]</span>, <span id="id4">[<a class="reference internal" href="../zreferences.html#id35">HS80</a>]</span>, <span id="id5">[<a class="reference internal" href="../zreferences.html#id36">Orf88</a>]</span>, <span id="id6">[<a class="reference internal" href="../zreferences.html#id37">AP91</a>]</span>, and <span id="id7">[<a class="reference internal" href="../zreferences.html#id38">Mut60</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">Statistics</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="infinite-horizon-prediction-and-filtering-problems">
<h2><a class="toc-backref" href="#id20"><span class="section-number">59.2. </span>Infinite Horizon Prediction and Filtering Problems</a><a class="headerlink" href="#infinite-horizon-prediction-and-filtering-problems" title="Permalink to this headline">¶</a></h2>
<p>We pose two related prediction and filtering problems.</p>
<p>We let <span class="math notranslate nohighlight">\(Y_t\)</span> be a univariate <span class="math notranslate nohighlight">\(m^{\rm th}\)</span> order moving average, covariance stationary stochastic process,</p>
<div class="math notranslate nohighlight" id="equation-eq-24">
<span class="eqno">(59.1)<a class="headerlink" href="#equation-eq-24" title="Permalink to this equation">¶</a></span>\[Y_t = d(L) u_t\]</div>
<p>where <span class="math notranslate nohighlight">\(d(L) = \sum^m_{j=0} d_j L^j\)</span>, and <span class="math notranslate nohighlight">\(u_t\)</span> is a serially uncorrelated stationary random process satisfying</p>
<div class="math notranslate nohighlight" id="equation-eq-25">
<span class="eqno">(59.2)<a class="headerlink" href="#equation-eq-25" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    \mathbb{E} u_t &amp;= 0\\
    \mathbb{E} u_t u_s &amp;=
    \begin{cases}
        1 &amp; \text{ if } t = s \\
        0 &amp; \text{ otherwise}
    \end{cases}
\end{aligned}\end{split}\]</div>
<p>We impose no conditions on the zeros of <span class="math notranslate nohighlight">\(d(z)\)</span>.</p>
<p>A second covariance stationary process is <span class="math notranslate nohighlight">\(X_t\)</span> given by</p>
<div class="math notranslate nohighlight" id="equation-eq-26">
<span class="eqno">(59.3)<a class="headerlink" href="#equation-eq-26" title="Permalink to this equation">¶</a></span>\[X_t = Y_t + \varepsilon_t\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon_t\)</span> is a serially uncorrelated stationary
random process with <span class="math notranslate nohighlight">\(\mathbb{E} \varepsilon_t = 0\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E} \varepsilon_t \varepsilon_s\)</span> = <span class="math notranslate nohighlight">\(0\)</span> for all distinct <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>We also assume that <span class="math notranslate nohighlight">\(\mathbb{E} \varepsilon_t u_s = 0\)</span> for all <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>The <strong>linear least squares prediction problem</strong> is to find the <span class="math notranslate nohighlight">\(L_2\)</span>
random variable <span class="math notranslate nohighlight">\(\hat X_{t+j}\)</span> among linear combinations of
<span class="math notranslate nohighlight">\(\{ X_t,\  X_{t-1},
\ldots \}\)</span> that minimizes <span class="math notranslate nohighlight">\(\mathbb{E}(\hat X_{t+j} - X_{t+j})^2\)</span>.</p>
<p>That is, the problem is to find a <span class="math notranslate nohighlight">\(\gamma_j (L) = \sum^\infty_{k=0} \gamma_{jk}\, L^k\)</span> such that <span class="math notranslate nohighlight">\(\sum^\infty_{k=0} \vert \gamma_{jk} \vert^2 &lt; \infty\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E} [\gamma_j \, (L) X_t -X_{t+j}]^2\)</span> is minimized.</p>
<p>The <strong>linear least squares filtering problem</strong> is to find a <span class="math notranslate nohighlight">\(b\,(L) = \sum^\infty_{j=0} b_j\, L^j\)</span> such that <span class="math notranslate nohighlight">\(\sum^\infty_{j=0}\vert b_j \vert^2 &lt; \infty\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E} [b\, (L) X_t -Y_t ]^2\)</span> is minimized.</p>
<p>Interesting versions of these problems related to the permanent income theory were studied by <span id="id8">[<a class="reference internal" href="../zreferences.html#id38">Mut60</a>]</span>.</p>
<div class="section" id="problem-formulation">
<h3><span class="section-number">59.2.1. </span>Problem formulation<a class="headerlink" href="#problem-formulation" title="Permalink to this headline">¶</a></h3>
<p>These problems are solved as follows.</p>
<p>The covariograms of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X\)</span> and their cross covariogram are, respectively,</p>
<div class="math notranslate nohighlight" id="equation-eq-27">
<span class="eqno">(59.4)<a class="headerlink" href="#equation-eq-27" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    C_X (\tau) &amp;= \mathbb{E}X_t X_{t-\tau} \\
    C_Y (\tau) &amp;= \mathbb{E}Y_t Y_{t-\tau}  \qquad \tau = 0, \pm 1, \pm 2, \ldots \\
    C_{Y,X} (\tau) &amp;= \mathbb{E}Y_t X_{t-\tau}
\end{aligned}\end{split}\]</div>
<p>The covariance and cross covariance generating functions are defined as</p>
<div class="math notranslate nohighlight" id="equation-eq-28">
<span class="eqno">(59.5)<a class="headerlink" href="#equation-eq-28" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    g_X(z) &amp;= \sum^\infty_{\tau = - \infty} C_X (\tau) z^\tau \\
    g_Y(z) &amp;= \sum^\infty_{\tau = - \infty} C_Y (\tau) z^\tau \\
    g_{YX} (z) &amp;= \sum^\infty_{\tau = - \infty} C_{YX} (\tau) z^\tau
\end{aligned}\end{split}\]</div>
<p>The generating functions can be computed by using the following facts.</p>
<p>Let <span class="math notranslate nohighlight">\(v_{1t}\)</span> and <span class="math notranslate nohighlight">\(v_{2t}\)</span> be two mutually and serially uncorrelated white noises with unit variances.</p>
<p>That is, <span class="math notranslate nohighlight">\(\mathbb{E}v^2_{1t} = \mathbb{E}v^2_{2t} = 1, \mathbb{E}v_{1t} = \mathbb{E}v_{2t} = 0, \mathbb{E}v_{1t} v_{2s} = 0\)</span> for all <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(s\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E}v_{1t} v_{1t-j} = \mathbb{E}v_{2t} v_{2t-j} = 0\)</span> for all <span class="math notranslate nohighlight">\(j \not = 0\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(x_t\)</span> and <span class="math notranslate nohighlight">\(y_t\)</span> be two random process given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    y_t &amp;= A(L) v_{1t} + B(L) v_{2t} \\
    x_t &amp;= C(L) v_{1t} + D(L) v_{2t}
\end{aligned}
\end{split}\]</div>
<p>Then, as shown for example in <span id="id9">[<a class="reference internal" href="../zreferences.html#id123">Sar87</a>]</span> [ch. XI], it is true that</p>
<div class="math notranslate nohighlight" id="equation-eq-29">
<span class="eqno">(59.6)<a class="headerlink" href="#equation-eq-29" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    g_y(z) &amp;= A(z) A(z^{-1}) + B (z) B(z^{-1}) \\
    g_x (z) &amp;= C(z) C(z^{-1}) + D(z) D(z^{-1}) \\
    g_{yx} (z) &amp;= A(z) C(z^{-1}) + B(z) D(z^{-1})
\end{aligned}\end{split}\]</div>
<p>Applying these formulas to <a class="reference internal" href="#equation-eq-24">(59.1)</a> – <a class="reference internal" href="#equation-eq-27">(59.4)</a>, we have</p>
<div class="math notranslate nohighlight" id="equation-eq-30">
<span class="eqno">(59.7)<a class="headerlink" href="#equation-eq-30" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    g_Y(z) &amp;= d(z)d(z^{-1}) \\
    g_X(z) &amp;= d(z)d(z^{-1}) + h\\
    g_{YX} (z) &amp;= d(z) d(z^{-1})
\end{aligned}\end{split}\]</div>
<p>The key step in obtaining solutions to our problems is to factor the covariance generating function  <span class="math notranslate nohighlight">\(g_X(z)\)</span> of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>The solutions of our problems are given by formulas due to Wiener and Kolmogorov.</p>
<p>These formulas utilize the Wold moving average representation of the <span class="math notranslate nohighlight">\(X_t\)</span> process,</p>
<div class="math notranslate nohighlight" id="equation-eq-31">
<span class="eqno">(59.8)<a class="headerlink" href="#equation-eq-31" title="Permalink to this equation">¶</a></span>\[X_t = c\,(L)\,\eta_t\]</div>
<p>where <span class="math notranslate nohighlight">\(c(L) = \sum^m_{j=0} c_j\, L^j\)</span>, with</p>
<div class="math notranslate nohighlight" id="equation-eq-32">
<span class="eqno">(59.9)<a class="headerlink" href="#equation-eq-32" title="Permalink to this equation">¶</a></span>\[c_0 \eta_t
= X_t - \mathbb{\hat E} [X_t \vert X_{t-1}, X_{t-2}, \ldots]\]</div>
<p>Here <span class="math notranslate nohighlight">\(\mathbb{\hat E}\)</span> is the linear least squares projection operator.</p>
<p>Equation <a class="reference internal" href="#equation-eq-32">(59.9)</a>  is the condition that <span class="math notranslate nohighlight">\(c_0 \eta_t\)</span> can be the one-step ahead error in predicting <span class="math notranslate nohighlight">\(X_t\)</span> from its own past values.</p>
<p>Condition <a class="reference internal" href="#equation-eq-32">(59.9)</a>  requires that <span class="math notranslate nohighlight">\(\eta_t\)</span> lie in the closed
linear space spanned by <span class="math notranslate nohighlight">\([X_t,\  X_{t-1}, \ldots]\)</span>.</p>
<p>This will be true if and only if the zeros of <span class="math notranslate nohighlight">\(c(z)\)</span> do not lie inside the unit circle.</p>
<p>It is an implication of <a class="reference internal" href="#equation-eq-32">(59.9)</a> that <span class="math notranslate nohighlight">\(\eta_t\)</span> is a serially
uncorrelated random process, and that a normalization can be imposed so
that <span class="math notranslate nohighlight">\(\mathbb{E}\eta_t^2 = 1\)</span>.</p>
<p>Consequently, an implication of <a class="reference internal" href="#equation-eq-31">(59.8)</a>  is
that the covariance generating function of <span class="math notranslate nohighlight">\(X_t\)</span> can be expressed
as</p>
<div class="math notranslate nohighlight" id="equation-eq-33">
<span class="eqno">(59.10)<a class="headerlink" href="#equation-eq-33" title="Permalink to this equation">¶</a></span>\[g_X(z) = c\,(z)\,c\,(z^{-1})\]</div>
<p>It remains to discuss how <span class="math notranslate nohighlight">\(c(L)\)</span> is to be computed.</p>
<p>Combining <a class="reference internal" href="#equation-eq-29">(59.6)</a>  and <a class="reference internal" href="#equation-eq-33">(59.10)</a>  gives</p>
<div class="math notranslate nohighlight" id="equation-eq-34">
<span class="eqno">(59.11)<a class="headerlink" href="#equation-eq-34" title="Permalink to this equation">¶</a></span>\[d(z) \,d(z^{-1}) + h = c \, (z) \,c\,(z^{-1})\]</div>
<p>Therefore, we have already showed constructively how to factor the covariance generating function <span class="math notranslate nohighlight">\(g_X(z) = d(z)\,d\,(z^{-1}) + h\)</span>.</p>
<p>We now introduce the <strong>annihilation operator</strong>:</p>
<div class="math notranslate nohighlight" id="equation-eq-35">
<span class="eqno">(59.12)<a class="headerlink" href="#equation-eq-35" title="Permalink to this equation">¶</a></span>\[\left[
    \sum^\infty_{j= - \infty} f_j\, L^j
\right]_+
\equiv \sum^\infty_{j=0} f_j\,L^j\]</div>
<p>In words, <span class="math notranslate nohighlight">\([\phantom{00}]_+\)</span> means “ignore negative powers of <span class="math notranslate nohighlight">\(L\)</span>”.</p>
<p>We have defined the solution of the prediction problem as <span class="math notranslate nohighlight">\(\mathbb{\hat E} [X_{t+j} \vert X_t,\, X_{t-1}, \ldots] = \gamma_j\, (L) X_t\)</span>.</p>
<p>Assuming that the roots of <span class="math notranslate nohighlight">\(c(z) = 0\)</span> all lie outside the unit circle, the Wiener-Kolmogorov formula for <span class="math notranslate nohighlight">\(\gamma_j (L)\)</span> holds:</p>
<div class="math notranslate nohighlight" id="equation-eq-36">
<span class="eqno">(59.13)<a class="headerlink" href="#equation-eq-36" title="Permalink to this equation">¶</a></span>\[\gamma_j\, (L) =
\left[
    {c (L) \over L^j}
\right]_+ c\,(L)^{-1}\]</div>
<p>We have defined the solution of the filtering problem as <span class="math notranslate nohighlight">\(\mathbb{\hat E}[Y_t \mid X_t, X_{t-1}, \ldots] = b (L)X_t\)</span>.</p>
<p>The Wiener-Kolomogorov formula for <span class="math notranslate nohighlight">\(b(L)\)</span> is</p>
<div class="math notranslate nohighlight">
\[
b(L) = \left({g_{YX} (L) \over c(L^{-1})}\right)_+ c(L)^{-1}
\]</div>
<p>or</p>
<div class="math notranslate nohighlight" id="equation-eq-37">
<span class="eqno">(59.14)<a class="headerlink" href="#equation-eq-37" title="Permalink to this equation">¶</a></span>\[b(L) = \left[ {d(L)d(L^{-1}) \over c(L^{-1})} \right]_+ c(L)^{-1}\]</div>
<p>Formulas <a class="reference internal" href="#equation-eq-36">(59.13)</a> and <a class="reference internal" href="#equation-eq-37">(59.14)</a>  are discussed in detail in  <span id="id10">[<a class="reference internal" href="../zreferences.html#id16">Whi83</a>]</span> and <span id="id11">[<a class="reference internal" href="../zreferences.html#id123">Sar87</a>]</span>.</p>
<p>The interested reader can there find several examples of the use of these formulas in economics
Some classic examples using these formulas are due to <span id="id12">[<a class="reference internal" href="../zreferences.html#id38">Mut60</a>]</span>.</p>
<p>As an example of the usefulness of formula <a class="reference internal" href="#equation-eq-37">(59.14)</a>, we let <span class="math notranslate nohighlight">\(X_t\)</span> be a stochastic process with Wold moving average representation</p>
<div class="math notranslate nohighlight">
\[
X_t = c(L) \eta_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{E}\eta^2_t = 1, \hbox { and } c_0 \eta_t = X_t - \mathbb{\hat E} [X_t \vert X_{t-1}, \ldots], c (L) = \sum^m_{j=0} c_j L\)</span>.</p>
<p>Suppose that at time <span class="math notranslate nohighlight">\(t\)</span>, we wish to predict a geometric sum of future <span class="math notranslate nohighlight">\(X\)</span>’s, namely</p>
<div class="math notranslate nohighlight">
\[
y_t \equiv \sum^\infty_{j=0} \delta^j X_{t+j} = {1 \over 1 - \delta L^{-1}}
X_t
\]</div>
<p>given knowledge of <span class="math notranslate nohighlight">\(X_t, X_{t-1}, \ldots\)</span>.</p>
<p>We shall use <a class="reference internal" href="#equation-eq-37">(59.14)</a>  to obtain the answer.</p>
<p>Using the standard formulas  <a class="reference internal" href="#equation-eq-29">(59.6)</a>, we have that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    g_{yx}(z) &amp;= (1-\delta z^{-1})c(z) c (z^{-1}) \\
    g_x (z) &amp;= c(z) c (z^{-1})
\end{aligned}
\end{split}\]</div>
<p>Then <a class="reference internal" href="#equation-eq-37">(59.14)</a>  becomes</p>
<div class="math notranslate nohighlight" id="equation-eq-38">
<span class="eqno">(59.15)<a class="headerlink" href="#equation-eq-38" title="Permalink to this equation">¶</a></span>\[b(L)=\left[{c(L)\over 1-\delta L^{-1}}\right]_+ c(L)^{-1}\]</div>
<p>In order to evaluate the term in the annihilation operator, we use the following result from <span id="id13">[<a class="reference internal" href="../zreferences.html#id35">HS80</a>]</span>.</p>
<p><strong>Proposition</strong> Let</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(g(z) = \sum^\infty_{j=0} g_j \, z^j\)</span> where <span class="math notranslate nohighlight">\(\sum^\infty_{j=0} \vert g_j \vert^2 &lt; + \infty\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(h\,(z^{-1}) =\)</span> <span class="math notranslate nohighlight">\((1- \delta_1 z^{-1}) \ldots (1-\delta_n z^{-1})\)</span>, where <span class="math notranslate nohighlight">\(\vert \delta_j \vert &lt; 1\)</span>, for <span class="math notranslate nohighlight">\(j = 1, \ldots, n\)</span></p></li>
</ul>
<p>Then</p>
<div class="math notranslate nohighlight" id="equation-eq-39">
<span class="eqno">(59.16)<a class="headerlink" href="#equation-eq-39" title="Permalink to this equation">¶</a></span>\[\left[{g(z)\over h(z^{-1})}\right]_+ = {g(z)\over h(z^{-1})} - \sum^n_{j=1}
\ {\delta_j g (\delta_j) \over \prod^n_{k=1 \atop k \not = j} (\delta_j -
\delta_k)} \ \left({1 \over z- \delta_j}\right)\]</div>
<p>and, alternatively,</p>
<div class="math notranslate nohighlight" id="equation-eq-40">
<span class="eqno">(59.17)<a class="headerlink" href="#equation-eq-40" title="Permalink to this equation">¶</a></span>\[\left[
    {g(z)\over h(z^{-1})}
\right]_+
=\sum^n_{j=1} B_j
\left(
    {zg(z)-\delta_j g (\delta_j) \over z- \delta_j}
\right)\]</div>
<p>where <span class="math notranslate nohighlight">\(B_j = 1 / \prod^n_{k=1\atop k+j} (1 - \delta_k / \delta_j)\)</span>.</p>
<p>Applying formula <a class="reference internal" href="#equation-eq-40">(59.17)</a>  of the proposition to evaluating  <a class="reference internal" href="#equation-eq-38">(59.15)</a>  with <span class="math notranslate nohighlight">\(g(z) = c(z)\)</span> and <span class="math notranslate nohighlight">\(h(z^{-1}) = 1 - \delta z^{-1}\)</span> gives</p>
<div class="math notranslate nohighlight">
\[
b(L)=\left[{Lc(L)-\delta c(\delta)\over L-\delta}\right] c(L)^{-1}
\]</div>
<p>or</p>
<div class="math notranslate nohighlight">
\[
b(L) =
\left[
    {1-\delta c (\delta) L^{-1} c (L)^{-1}\over 1-\delta L^{-1}}
\right]
\]</div>
<p>Thus, we have</p>
<div class="math notranslate nohighlight" id="equation-eq-41">
<span class="eqno">(59.18)<a class="headerlink" href="#equation-eq-41" title="Permalink to this equation">¶</a></span>\[\mathbb{\hat E}
\left[
    \sum^\infty_{j=0} \delta^j X_{t+j}\vert X_t,\, x_{t-1},
    \ldots
\right]  =
\left[
    {1-\delta c (\delta) L^{-1} c(L)^{-1} \over 1 - \delta L^{-1}}
\right]
\, X_t\]</div>
<p>This formula is useful in solving stochastic versions of problem 1 of lecture <a class="reference internal" href="lu_tricks.html"><span class="doc">Classical Control with Linear Algebra</span></a> in which the randomness emerges because <span class="math notranslate nohighlight">\(\{a_t\}\)</span> is a stochastic
process.</p>
<p>The problem is to maximize</p>
<div class="math notranslate nohighlight" id="equation-eq-42">
<span class="eqno">(59.19)<a class="headerlink" href="#equation-eq-42" title="Permalink to this equation">¶</a></span>\[\mathbb{E}_0
\lim_{N \rightarrow \infty}\
\sum^N_{t-0} \beta^t
\left[
    a_t\, y_t - {1 \over 2}\ hy^2_t-{1 \over 2}\ [d(L)y_t]^2
\right]\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{E}_t\)</span> is mathematical expectation conditioned on information
known at <span class="math notranslate nohighlight">\(t\)</span>, and where <span class="math notranslate nohighlight">\(\{ a_t\}\)</span> is a covariance
stationary stochastic process with Wold moving average representation</p>
<div class="math notranslate nohighlight">
\[
a_t = c(L)\, \eta_t
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
c(L) = \sum^{\tilde n}_{j=0} c_j L^j
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\eta_t =
a_t - \mathbb{\hat E} [a_t \vert a_{t-1}, \ldots]
\]</div>
<p>The problem is to maximize <a class="reference internal" href="#equation-eq-42">(59.19)</a>  with respect to a contingency plan
expressing <span class="math notranslate nohighlight">\(y_t\)</span> as a function of information known at <span class="math notranslate nohighlight">\(t\)</span>,
which is assumed to be
<span class="math notranslate nohighlight">\((y_{t-1},\  y_{t-2}, \ldots, a_t, \ a_{t-1}, \ldots)\)</span>.</p>
<p>The solution of this problem can be achieved in two steps.</p>
<p>First, ignoring the uncertainty, we can solve the problem assuming that <span class="math notranslate nohighlight">\(\{a_t\}\)</span> is a known sequence.</p>
<p>The solution is, from above,</p>
<div class="math notranslate nohighlight">
\[
c(L) y_t = c(\beta L^{-1})^{-1} a_t
\]</div>
<p>or</p>
<div class="math notranslate nohighlight" id="equation-eq-43">
<span class="eqno">(59.20)<a class="headerlink" href="#equation-eq-43" title="Permalink to this equation">¶</a></span>\[(1-\lambda_1 L) \ldots (1 - \lambda_m L) y_t
= \sum^m_{j=1} A_j
\sum^\infty_{k=0} (\lambda_j \beta)^k\, a_{t+k}\]</div>
<p>Second, the solution of the problem under uncertainty is obtained by
replacing the terms on the right-hand side of the above expressions with
their linear least squares predictors.</p>
<p>Using <a class="reference internal" href="#equation-eq-41">(59.18)</a> and <a class="reference internal" href="#equation-eq-43">(59.20)</a>, we have
the following solution</p>
<div class="math notranslate nohighlight">
\[
(1-\lambda_1 L) \ldots (1-\lambda_m L) y_t
=
\sum^m_{j=1} A_j
 \left[
     \frac{1-\beta \lambda_j \, c (\beta \lambda_j) L^{-1} c(L)^{-1} }
     { 1-\beta \lambda_j L^{-1} }
 \right] a_t
\]</div>
</div>
</div>
<div class="section" id="finite-dimensional-prediction">
<h2><a class="toc-backref" href="#id21"><span class="section-number">59.3. </span>Finite Dimensional Prediction</a><a class="headerlink" href="#finite-dimensional-prediction" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\((x_1, x_2, \ldots, x_T)^\prime = x\)</span> be a <span class="math notranslate nohighlight">\(T \times 1\)</span> vector of random variables with mean <span class="math notranslate nohighlight">\(\mathbb{E} x = 0\)</span> and covariance matrix <span class="math notranslate nohighlight">\(\mathbb{E} xx^\prime = V\)</span>.</p>
<p>Here <span class="math notranslate nohighlight">\(V\)</span> is a <span class="math notranslate nohighlight">\(T \times T\)</span> positive definite matrix.</p>
<p>We shall regard the random variables as being
ordered in time, so that <span class="math notranslate nohighlight">\(x_t\)</span> is thought of as the value of some
economic variable at time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>For example, <span class="math notranslate nohighlight">\(x_t\)</span> could be generated by the random process described  by the Wold representation presented in equation <a class="reference internal" href="#equation-eq-31">(59.8)</a>.</p>
<p>In this case, <span class="math notranslate nohighlight">\(V_{ij}\)</span> is given by the coefficient on <span class="math notranslate nohighlight">\(z^{\mid i-j \mid}\)</span> in the expansion of <span class="math notranslate nohighlight">\(g_x (z) = d(z) \, d(z^{-1}) + h\)</span>, which equals
<span class="math notranslate nohighlight">\(h+\sum^\infty_{k=0} d_k d_{k+\mid i-j \mid}\)</span>.</p>
<p>We shall be interested in constructing <span class="math notranslate nohighlight">\(j\)</span> step ahead linear least squares predictors of the form</p>
<div class="math notranslate nohighlight">
\[
\mathbb{\hat E}
\left[
    x_T\vert x_{T-j}, x_{T-j + 1}, \ldots, x_1
\right]
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{\hat E}\)</span> is the linear least squares projection operator.</p>
<p>The solution of this problem can be exhibited by first constructing an
orthonormal basis of random variables <span class="math notranslate nohighlight">\(\varepsilon\)</span> for <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(V\)</span> is a positive definite and symmetric, we know that there
exists a (Cholesky) decomposition of <span class="math notranslate nohighlight">\(V\)</span> such that</p>
<div class="math notranslate nohighlight">
\[
V = L^{-1} (L^{-1})^\prime
\]</div>
<p>or</p>
<div class="math notranslate nohighlight">
\[
L \, V \, L^\prime = I
\]</div>
<p>where <span class="math notranslate nohighlight">\(L\)</span> is lower-trangular, and therefore so is <span class="math notranslate nohighlight">\(L^{-1}\)</span>.</p>
<p>Form the random variable <span class="math notranslate nohighlight">\(Lx = \varepsilon\)</span>.</p>
<p>Then <span class="math notranslate nohighlight">\(\varepsilon\)</span> is an orthonormal basis for <span class="math notranslate nohighlight">\(x\)</span>, since <span class="math notranslate nohighlight">\(L\)</span> is nonsingular, and <span class="math notranslate nohighlight">\(\mathbb{E} \, \varepsilon \, \varepsilon^\prime =
L \mathbb{E} xx^\prime L^\prime = I\)</span>.</p>
<p>It is convenient to write out the equations <span class="math notranslate nohighlight">\(Lx = \varepsilon\)</span> and <span class="math notranslate nohighlight">\(L^{-1} \varepsilon = x\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-53">
<span class="eqno">(59.21)<a class="headerlink" href="#equation-eq-53" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    L_{11} x_1 &amp;= \varepsilon_1 \\
    L_{21}x_1 + L_{22} x_2 &amp;= \varepsilon_2 \\ \, \vdots \\
    L_{T1} \, x_1 \, \ldots \, + L_{TTx_T} &amp;= \varepsilon_T
\end{aligned}\end{split}\]</div>
<p>or</p>
<div class="math notranslate nohighlight" id="equation-eq-54">
<span class="eqno">(59.22)<a class="headerlink" href="#equation-eq-54" title="Permalink to this equation">¶</a></span>\[\sum^{t-1}_{j=0} L_{t,t-j}\, x_{t-j} = \varepsilon_t, \quad t = 1, \, 2, \ldots T\]</div>
<p>We also have</p>
<div class="math notranslate nohighlight" id="equation-eq-55">
<span class="eqno">(59.23)<a class="headerlink" href="#equation-eq-55" title="Permalink to this equation">¶</a></span>\[x_t = \sum^{t-1}_{j=0} L^{-1}_{t,t-j}\, \varepsilon_{t-j}\ .\]</div>
<p>Notice from <a class="reference internal" href="#equation-eq-55">(59.23)</a> that <span class="math notranslate nohighlight">\(x_t\)</span> is in the space spanned by
<span class="math notranslate nohighlight">\(\varepsilon_t, \, \varepsilon_{t-1}, \ldots, \varepsilon_1\)</span>, and from <a class="reference internal" href="#equation-eq-54">(59.22)</a>   that
<span class="math notranslate nohighlight">\(\varepsilon_t\)</span> is in the space spanned by <span class="math notranslate nohighlight">\(x_t,\, x_{t-1}, \ldots,\, x_1\)</span>.</p>
<p>Therefore, we have that for <span class="math notranslate nohighlight">\(t-1\geq m \geq 1\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-56">
<span class="eqno">(59.24)<a class="headerlink" href="#equation-eq-56" title="Permalink to this equation">¶</a></span>\[\mathbb{\hat E}
[ x_t \mid x_{t-m},\, x_{t-m-1}, \ldots, x_1 ] =
\mathbb{\hat E}
[x_t \mid \varepsilon_{t-m}, \varepsilon_{t-m-1},\ldots, \varepsilon_1]\]</div>
<p>For <span class="math notranslate nohighlight">\(t-1 \geq m \geq 1\)</span> rewrite <a class="reference internal" href="#equation-eq-55">(59.23)</a>  as</p>
<div class="math notranslate nohighlight" id="equation-eq-57">
<span class="eqno">(59.25)<a class="headerlink" href="#equation-eq-57" title="Permalink to this equation">¶</a></span>\[x_t = \sum^{m-1}_{j=0} L_{t,t-j}^{-1}\, \varepsilon_{t-j} + \sum^{t-1}_{j=m}
L^{-1}_{t, t-j}\, \varepsilon_{t-j}\]</div>
<p>Representation <a class="reference internal" href="#equation-eq-57">(59.25)</a>  is an orthogonal decomposition of <span class="math notranslate nohighlight">\(x_t\)</span> into a part <span class="math notranslate nohighlight">\(\sum^{t-1}_{j=m} L_{t, t-j}^{-1}\, \varepsilon_{t-j}\)</span> that lies in the space spanned by
<span class="math notranslate nohighlight">\([x_{t-m},\, x_{t-m+1},\, \ldots, x_1]\)</span>, and an orthogonal
component not in this space.</p>
<div class="section" id="implementation">
<h3><span class="section-number">59.3.1. </span>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h3>
<p>Code that computes solutions to  LQ control and filtering problems  using the methods described here and in <a class="reference internal" href="lu_tricks.html"><span class="doc">Classical Control with Linear Algebra</span></a> can be found in the file <a class="reference external" href="https://github.com/QuantEcon/QuantEcon.lectures.code/blob/master/lu_tricks/control_and_filter.jl">control_and_filter.jl</a>.</p>
<p>Here’s how it looks</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Polynomials</span><span class="o">.</span><span class="n">PolyCompat</span><span class="p">,</span> <span class="n">LinearAlgebra</span>
<span class="k">import</span> <span class="n">Polynomials</span><span class="o">.</span><span class="n">PolyCompat</span><span class="o">:</span> <span class="n">roots</span><span class="p">,</span> <span class="n">coeffs</span>

<span class="k">function</span> <span class="n">LQFilter</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">y_m</span><span class="p">;</span>
                  <span class="n">r</span> <span class="o">=</span> <span class="nb">nothing</span><span class="p">,</span>
                  <span class="n">β</span> <span class="o">=</span> <span class="nb">nothing</span><span class="p">,</span>
                  <span class="n">h_eps</span> <span class="o">=</span> <span class="nb">nothing</span><span class="p">)</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">m</span> <span class="o">==</span> <span class="n">length</span><span class="p">(</span><span class="n">y_m</span><span class="p">)</span> <span class="o">||</span>
        <span class="n">throw</span><span class="p">(</span><span class="kt">ArgumentError</span><span class="p">(</span><span class="s">&quot;y_m and d must be of same length = </span><span class="si">$m</span><span class="s">&quot;</span><span class="p">))</span>

    <span class="c"># define the coefficients of ϕ up front</span>
    <span class="n">ϕ</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="o">-</span><span class="n">m</span><span class="o">:</span><span class="n">m</span>
        <span class="n">ϕ</span><span class="p">[</span><span class="n">m</span><span class="o">-</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">diag</span><span class="p">(</span><span class="n">d</span><span class="o">*</span><span class="n">d</span><span class="o">&#39;</span><span class="p">,</span> <span class="o">-</span><span class="n">i</span><span class="p">))</span>
    <span class="k">end</span>
    <span class="n">ϕ</span><span class="p">[</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">ϕ</span><span class="p">[</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">h</span>

    <span class="c"># if r is given calculate the vector ϕ_r</span>
    <span class="k">if</span> <span class="n">isnothing</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">nothing</span>
        <span class="n">ϕ_r</span> <span class="o">=</span> <span class="nb">nothing</span>
    <span class="k">else</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">ϕ_r</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="o">-</span><span class="n">k</span><span class="o">:</span><span class="n">k</span>
            <span class="n">ϕ_r</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">diag</span><span class="p">(</span><span class="n">r</span><span class="o">*</span><span class="n">r</span><span class="o">&#39;</span><span class="p">,</span> <span class="o">-</span><span class="n">i</span><span class="p">))</span>
        <span class="k">end</span>

        <span class="k">if</span> <span class="n">isnothing</span><span class="p">(</span><span class="n">h_eps</span><span class="p">)</span> <span class="o">==</span> <span class="nb">false</span>
            <span class="n">ϕ_r</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">ϕ_r</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">h_eps</span>
        <span class="k">end</span>
    <span class="k">end</span>

    <span class="c"># if β is given, define the transformed variables</span>
    <span class="k">if</span> <span class="n">isnothing</span><span class="p">(</span><span class="n">β</span><span class="p">)</span>
        <span class="n">β</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">β</span><span class="o">.^</span><span class="p">(</span><span class="n">collect</span><span class="p">(</span><span class="mi">0</span><span class="o">:</span><span class="n">m</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span>
        <span class="n">y_m</span> <span class="o">=</span> <span class="n">y_m</span> <span class="o">*</span> <span class="n">β</span><span class="o">.^</span><span class="p">(</span><span class="o">-</span> <span class="n">collect</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">end</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="n">y_m</span> <span class="o">=</span> <span class="n">y_m</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="p">,</span> <span class="n">ϕ</span> <span class="o">=</span> <span class="n">ϕ</span><span class="p">,</span> <span class="n">β</span> <span class="o">=</span> <span class="n">β</span><span class="p">,</span>
            <span class="n">ϕ_r</span> <span class="o">=</span> <span class="n">ϕ_r</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">construct_W_and_Wm</span><span class="p">(</span><span class="n">lqf</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

    <span class="n">d</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">lqf</span><span class="o">.</span><span class="n">d</span><span class="p">,</span> <span class="n">lqf</span><span class="o">.</span><span class="n">m</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">W_m</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

    <span class="c"># terminal conditions</span>
    <span class="n">D_m1</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

    <span class="c"># (1) constuct the D_{m+1} matrix using the formula</span>

    <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="k">in</span> <span class="n">j</span><span class="o">:</span><span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">D_m1</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">end</span>
    <span class="k">end</span>

    <span class="c"># Make the matrix symmetric</span>
    <span class="n">D_m1</span> <span class="o">=</span> <span class="n">D_m1</span> <span class="o">+</span> <span class="n">D_m1</span><span class="o">&#39;</span> <span class="o">-</span> <span class="n">Diagonal</span><span class="p">(</span><span class="n">diag</span><span class="p">(</span><span class="n">D_m1</span><span class="p">))</span>

    <span class="c"># (2) Construct the M matrix using the entries of D_m1</span>

    <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span>
        <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">D_m1</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="n">j</span><span class="p">,</span> <span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">end</span>
    <span class="k">end</span>
    <span class="n">M</span>

    <span class="c"># Euler equations for t = 0, 1, ..., N-(m+1)</span>
    <span class="n">ϕ</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">lqf</span><span class="o">.</span><span class="n">ϕ</span><span class="p">,</span> <span class="n">lqf</span><span class="o">.</span><span class="n">h</span>

    <span class="n">W</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">D_m1</span> <span class="o">+</span> <span class="n">h</span> <span class="o">*</span> <span class="n">I</span>
    <span class="n">W</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span><span class="o">:</span><span class="p">(</span><span class="mi">2</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">M</span>

    <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="p">((</span><span class="n">m</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span><span class="o">:</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">m</span><span class="p">))</span>
        <span class="n">W</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="p">(</span><span class="mi">2</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ϕ</span><span class="o">&#39;</span>
    <span class="k">end</span>

    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span>
        <span class="n">W</span><span class="p">[</span><span class="n">N</span> <span class="o">-</span> <span class="n">m</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">,</span> <span class="k">end</span><span class="o">-</span><span class="p">(</span><span class="mi">2</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="k">end</span><span class="p">]</span> <span class="o">=</span> <span class="n">ϕ</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="k">end</span><span class="o">-</span><span class="n">i</span><span class="p">]</span>
    <span class="k">end</span>

    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span>
        <span class="n">W_m</span><span class="p">[</span><span class="n">N</span> <span class="o">-</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">ϕ</span><span class="p">[(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span><span class="o">:</span><span class="k">end</span><span class="p">]</span>
    <span class="k">end</span>

    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">W_m</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">roots_of_characteristic</span><span class="p">(</span><span class="n">lqf</span><span class="p">)</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">ϕ</span> <span class="o">=</span> <span class="n">lqf</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">lqf</span><span class="o">.</span><span class="n">ϕ</span>

    <span class="c"># Calculate the roots of the 2m-polynomial</span>
    <span class="n">ϕ_poly</span> <span class="o">=</span> <span class="n">Poly</span><span class="p">(</span><span class="n">ϕ</span><span class="p">[</span><span class="k">end</span><span class="o">:-</span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">proots</span> <span class="o">=</span> <span class="n">roots</span><span class="p">(</span><span class="n">ϕ_poly</span><span class="p">)</span>
    <span class="c"># sort the roots according to their length (in descending order)</span>
    <span class="n">roots_sorted</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">proots</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="n">abs</span><span class="p">)[</span><span class="k">end</span><span class="o">:-</span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span><span class="p">]</span>
   <span class="n">z_0</span> <span class="o">=</span> <span class="n">sum</span><span class="p">(</span><span class="n">ϕ</span><span class="p">)</span> <span class="o">/</span> <span class="n">polyval</span><span class="p">(</span><span class="n">poly</span><span class="p">(</span><span class="n">proots</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">z_1_to_m</span> <span class="o">=</span> <span class="n">roots_sorted</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">]</span>     <span class="c"># we need only those outside the unit circle</span>
    <span class="n">λ</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">./</span> <span class="n">z_1_to_m</span>
    <span class="k">return</span> <span class="n">z_1_to_m</span><span class="p">,</span> <span class="n">z_0</span><span class="p">,</span> <span class="n">λ</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">coeffs_of_c</span><span class="p">(</span><span class="n">lqf</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">lqf</span><span class="o">.</span><span class="n">m</span>
    <span class="n">z_1_to_m</span><span class="p">,</span> <span class="n">z_0</span><span class="p">,</span> <span class="n">λ</span> <span class="o">=</span> <span class="n">roots_of_characteristic</span><span class="p">(</span><span class="n">lqf</span><span class="p">)</span>
    <span class="n">c_0</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_0</span> <span class="o">*</span> <span class="n">prod</span><span class="p">(</span><span class="n">z_1_to_m</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span><span class="o">^</span><span class="n">m</span><span class="p">)</span><span class="o">^</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">c_coeffs</span> <span class="o">=</span> <span class="n">coeffs</span><span class="p">(</span><span class="n">poly</span><span class="p">(</span><span class="n">z_1_to_m</span><span class="p">))</span> <span class="o">*</span> <span class="n">z_0</span> <span class="o">/</span> <span class="n">c_0</span>
    <span class="k">return</span> <span class="n">c_coeffs</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">solution</span><span class="p">(</span><span class="n">lqf</span><span class="p">)</span>
    <span class="n">z_1_to_m</span><span class="p">,</span> <span class="n">z_0</span><span class="p">,</span> <span class="n">λ</span> <span class="o">=</span> <span class="n">roots_of_characteristic</span><span class="p">(</span><span class="n">lqf</span><span class="p">)</span>
    <span class="n">c_0</span> <span class="o">=</span> <span class="n">coeffs_of_c</span><span class="p">(</span><span class="n">lqf</span><span class="p">)[</span><span class="k">end</span><span class="p">]</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">lqf</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">λ</span><span class="o">/</span><span class="n">λ</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_0</span><span class="o">^</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">prod</span><span class="p">(</span><span class="n">denom</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="n">m</span> <span class="o">.!=</span> <span class="n">j</span><span class="p">])</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">λ</span><span class="p">,</span> <span class="n">A</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">construct_V</span><span class="p">(</span><span class="n">lqf</span><span class="p">;</span> <span class="n">N</span> <span class="o">=</span> <span class="nb">nothing</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">isnothing</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">error</span><span class="p">(</span><span class="s">&quot;N must be provided!!&quot;</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">if</span> <span class="o">!</span><span class="p">(</span><span class="n">N</span> <span class="k">isa</span> <span class="kt">Integer</span><span class="p">)</span>
        <span class="n">throw</span><span class="p">(</span><span class="kt">ArgumentError</span><span class="p">(</span><span class="s">&quot;N must be Integer!&quot;</span><span class="p">))</span>
    <span class="k">end</span>

    <span class="n">ϕ_r</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">lqf</span><span class="o">.</span><span class="n">ϕ_r</span><span class="p">,</span> <span class="n">lqf</span><span class="o">.</span><span class="n">k</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span>
        <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span>
            <span class="k">if</span> <span class="n">abs</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="n">j</span><span class="p">)</span> <span class="o">≤</span> <span class="n">k</span>
                <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">ϕ_r</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="n">abs</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="n">j</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">end</span>
        <span class="k">end</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">V</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">simulate_a</span><span class="p">(</span><span class="n">lqf</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">construct_V</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">MVNSampler</span><span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">V</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rand</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">predict</span><span class="p">(</span><span class="n">lqf</span><span class="p">,</span> <span class="n">a_hist</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">a_hist</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">construct_V</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">aux_matrix</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">aux_matrix</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span> <span class="p">,</span> <span class="mi">1</span><span class="o">:</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span> <span class="p">]</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">U</span><span class="o">&#39;</span>
    <span class="n">Ea_hist</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">L</span><span class="p">)</span> <span class="o">*</span> <span class="n">aux_matrix</span> <span class="o">*</span> <span class="n">L</span> <span class="o">*</span> <span class="n">a_hist</span>

    <span class="k">return</span> <span class="n">Ea_hist</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">optimal_y</span><span class="p">(</span><span class="n">lqf</span><span class="p">,</span> <span class="n">a_hist</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="nb">nothing</span><span class="p">)</span>
    <span class="n">β</span><span class="p">,</span> <span class="n">y_m</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">lqf</span><span class="o">.</span><span class="n">β</span><span class="p">,</span> <span class="n">lqf</span><span class="o">.</span><span class="n">y_m</span><span class="p">,</span> <span class="n">lqf</span><span class="o">.</span><span class="n">m</span>

    <span class="n">N</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">a_hist</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">W</span><span class="p">,</span> <span class="n">W_m</span> <span class="o">=</span> <span class="n">construct_W_and_Wm</span><span class="p">(</span><span class="n">lqf</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

    <span class="n">F</span> <span class="o">=</span> <span class="n">lu</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="kt">Val</span><span class="p">(</span><span class="nb">true</span><span class="p">))</span>

    <span class="n">L</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">F</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">diagm</span><span class="p">(</span><span class="mi">0</span> <span class="o">=&gt;</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="n">diag</span><span class="p">(</span><span class="n">U</span><span class="p">))</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">D</span> <span class="o">*</span> <span class="n">U</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">L</span> <span class="o">*</span> <span class="n">diagm</span><span class="p">(</span><span class="mi">0</span> <span class="o">=&gt;</span> <span class="mf">1.0</span> <span class="o">./</span> <span class="n">diag</span><span class="p">(</span><span class="n">D</span><span class="p">))</span>

    <span class="n">J</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">isnothing</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>                      <span class="c"># if the problem is deterministic</span>
        <span class="n">a_hist</span> <span class="o">=</span> <span class="n">J</span> <span class="o">*</span> <span class="n">a_hist</span>

        <span class="c"># transform the a sequence if β is given</span>
        <span class="k">if</span> <span class="n">β</span> <span class="o">!=</span> <span class="mi">1</span>
            <span class="n">a_hist</span> <span class="o">=</span>  <span class="n">reshape</span><span class="p">(</span><span class="n">a_hist</span> <span class="o">*</span> <span class="p">(</span><span class="n">β</span><span class="o">^</span><span class="p">(</span><span class="n">collect</span><span class="p">(</span><span class="n">N</span><span class="o">:</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">end</span>

        <span class="n">ā</span> <span class="o">=</span> <span class="n">a_hist</span> <span class="o">-</span> <span class="n">W_m</span> <span class="o">*</span> <span class="n">y_m</span>        <span class="c"># ā from the lecutre</span>
        <span class="n">Uy</span> <span class="o">=</span> <span class="o">\</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">ā</span><span class="p">)</span>                  <span class="c"># U @ ȳ = L^{-1}ā from the lecture</span>
        <span class="n">ȳ</span> <span class="o">=</span> <span class="o">\</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">Uy</span><span class="p">)</span>                  <span class="c"># ȳ = U^{-1}L^{-1}ā</span>
        <span class="c"># Reverse the order of ȳ with the matrix J</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">y_hist</span> <span class="o">=</span> <span class="n">J</span> <span class="o">*</span> <span class="n">vcat</span><span class="p">(</span><span class="n">ȳ</span><span class="p">,</span> <span class="n">y_m</span><span class="p">)</span>     <span class="c"># y_hist : concatenated y_m and ȳ</span>
        <span class="c"># transform the optimal sequence back if β is given</span>
        <span class="k">if</span> <span class="n">β</span> <span class="o">!=</span> <span class="mi">1</span>
            <span class="n">y_hist</span> <span class="o">=</span> <span class="n">y_hist</span> <span class="o">.*</span> <span class="n">β</span><span class="o">.^</span><span class="p">(</span><span class="o">-</span> <span class="n">collect</span><span class="p">(</span><span class="o">-</span><span class="n">m</span><span class="o">:</span><span class="n">N</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">end</span>

    <span class="k">else</span>                                  <span class="c"># if the problem is stochastic and we look at it</span>
        <span class="n">Ea_hist</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="n">a_hist</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">Ea_hist</span> <span class="o">=</span> <span class="n">J</span> <span class="o">*</span> <span class="n">Ea_hist</span>

        <span class="n">ā</span> <span class="o">=</span> <span class="n">Ea_hist</span> <span class="o">-</span> <span class="n">W_m</span> <span class="o">*</span> <span class="n">y_m</span>       <span class="c"># ā from the lecutre</span>
        <span class="n">Uy</span> <span class="o">=</span> <span class="o">\</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">ā</span><span class="p">)</span>                  <span class="c"># U @ ȳ = L^{-1}ā from the lecture</span>
        <span class="n">ȳ</span> <span class="o">=</span> <span class="o">\</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">Uy</span><span class="p">)</span>                  <span class="c"># ȳ = U^{-1}L^{-1}ā</span>

        <span class="c"># Reverse the order of ȳ with the matrix J</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">reverse</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dims</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">y_hist</span> <span class="o">=</span> <span class="n">J</span> <span class="o">*</span> <span class="n">vcat</span><span class="p">(</span><span class="n">ȳ</span><span class="p">,</span> <span class="n">y_m</span><span class="p">)</span>     <span class="c"># y_hist : concatenated y_m and ȳ</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">y_hist</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">ȳ</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>ArgumentError: Package Polynomials [f27b6e38-b328-58d1-80ce-0feddd5e7a45] is required but does not seem to be installed:
 - Run `Pkg.instantiate()` to install all recorded dependencies.


Stacktrace:
 [1] _require(pkg::Base.PkgId)
   @ Base ./loading.jl:990
 [2] require(uuidkey::Base.PkgId)
   @ Base ./loading.jl:914
 [3] require(into::Module, mod::Symbol)
   @ Base ./loading.jl:901
 [4] eval
   @ ./boot.jl:360 [inlined]
 [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)
   @ Base ./loading.jl:1094
</pre></div>
</div>
</div>
</div>
<p>Let’s use this code to tackle two interesting examples.</p>
</div>
<div class="section" id="example-1">
<h3><span class="section-number">59.3.2. </span>Example 1<a class="headerlink" href="#example-1" title="Permalink to this headline">¶</a></h3>
<p>Consider a stochastic process with moving average representation</p>
<div class="math notranslate nohighlight">
\[
x_t = (1 - 2 L) \varepsilon_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon_t\)</span> is a serially uncorrelated random process with mean zero and variance unity.</p>
<p>We want to use the Wiener-Kolmogorov formula <a class="reference internal" href="#equation-eq-36">(59.13)</a> to compute the linear least squares forecasts <span class="math notranslate nohighlight">\(\mathbb{E} [x_{t+j} \mid x_t, x_{t-1}, \ldots]\)</span>, for <span class="math notranslate nohighlight">\(j = 1,\, 2\)</span>.</p>
<p>We can do everything we want by setting <span class="math notranslate nohighlight">\(d = r\)</span>, generating an instance of LQFilter, then invoking pertinent methods of LQFilter</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y_m</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">]</span>
<span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">]</span>
<span class="n">h</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">LQFilter</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">y_m</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The Wold representation is computed by example.coefficients_of_c().</p>
<p>Let’s check that it “flips roots” as required</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">coeffs_of_c</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">roots_of_characteristic</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s form the covariance matrix of a time series vector of length <span class="math notranslate nohighlight">\(N\)</span>
and put it in <span class="math notranslate nohighlight">\(V\)</span>.</p>
<p>Then we’ll take a Cholesky decomposition of <span class="math notranslate nohighlight">\(V = L^{-1} L^{-1} = Li Li'\)</span> and use it to form the vector of “moving average representations” <span class="math notranslate nohighlight">\(x = Li \varepsilon\)</span> and the vector of “autoregressive representations” <span class="math notranslate nohighlight">\(L x = \varepsilon\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">V</span> <span class="o">=</span> <span class="n">construct_V</span><span class="p">(</span><span class="n">example</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice how the lower rows of the “moving average representations” are converging to the appropriate infinite history Wold representation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">F</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
<span class="n">Li</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">L</span>
</pre></div>
</div>
</div>
</div>
<p>Notice how the lower rows of the “autoregressive representations” are converging to the appropriate infinite history autoregressive representation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">L</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">Li</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Remark</strong> Let <span class="math notranslate nohighlight">\(\pi (z) = \sum^m_{j=0} \pi_j z^j\)</span> and let <span class="math notranslate nohighlight">\(z_1, \ldots,
z_k\)</span> be the zeros of <span class="math notranslate nohighlight">\(\pi (z)\)</span> that are inside the unit circle, <span class="math notranslate nohighlight">\(k &lt; m\)</span>.</p>
<p>Then define</p>
<div class="math notranslate nohighlight">
\[
\theta (z) = \pi (z) \Biggl( {(z_1 z-1) \over (z-z_1)} \Biggr)
\Biggl( { (z_2 z-1) \over (z-z_2) } \Biggr ) \ldots \Biggl({(z_kz-1) \over
(z-z_k) }\Biggr)
\]</div>
<p>The term multiplying <span class="math notranslate nohighlight">\(\pi (z)\)</span> is termed a “Blaschke factor”.</p>
<p>Then it can be proved directly that</p>
<div class="math notranslate nohighlight">
\[
\theta (z^{-1}) \theta (z) = \pi (z^{-1}) \pi (z)
\]</div>
<p>and that the zeros of <span class="math notranslate nohighlight">\(\theta (z)\)</span> are not inside the unit circle.</p>
</div>
<div class="section" id="example-2">
<h3><span class="section-number">59.3.3. </span>Example 2<a class="headerlink" href="#example-2" title="Permalink to this headline">¶</a></h3>
<p>Consider a stochastic process <span class="math notranslate nohighlight">\(X_t\)</span> with moving average
representation</p>
<div class="math notranslate nohighlight">
\[
X_t = (1 - \sqrt 2 L^2) \varepsilon_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon_t\)</span> is a serially uncorrelated random process
with mean zero and variance unity.</p>
<p>Let’s find a Wold moving average representation for <span class="math notranslate nohighlight">\(x_t\)</span>.</p>
<p>Let’s use the Wiener-Kolomogorov formula <a class="reference internal" href="#equation-eq-36">(59.13)</a> to compute the linear least squares forecasts
<span class="math notranslate nohighlight">\(\mathbb{\hat E}\left[X_{t+j} \mid X_{t-1}, \ldots\right] \hbox { for } j = 1,\, 2,\, 3\)</span>.</p>
<p>We proceed in the same way as example 1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">y_m</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">d</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
<span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
<span class="n">h</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">LQFilter</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">y_m</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">coeffs_of_c</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">roots_of_characteristic</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">V</span> <span class="o">=</span> <span class="n">construct_V</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">F</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
<span class="n">Li</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">L</span>
<span class="n">Li</span><span class="p">[</span><span class="k">end</span><span class="o">-</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">,</span> <span class="o">:</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">L</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">Li</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="prediction">
<h3><span class="section-number">59.3.4. </span>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">¶</a></h3>
<p>It immediately follows from the “orthogonality principle” of least squares (see <span id="id14">[<a class="reference internal" href="../zreferences.html#id37">AP91</a>]</span> or <span id="id15">[<a class="reference internal" href="../zreferences.html#id123">Sar87</a>]</span> [ch. X]) that</p>
<div class="math notranslate nohighlight" id="equation-eq-58">
<span class="eqno">(59.26)<a class="headerlink" href="#equation-eq-58" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    \mathbb{\hat E} &amp; [x_t \mid x_{t-m},\, x_{t-m+1}, \ldots x_1]
                    = \sum^{t-1}_{j=m} L^{-1}_{t,t-j}\, \varepsilon_{t-j} \\
               &amp; = [L_{t, 1}^{-1}\, L^{-1}_{t,2},\, \ldots, L^{-1}_{t,t-m}\ 0 \ 0 \ldots 0] L \, x
\end{aligned}\end{split}\]</div>
<p>This can be interpreted as a finite-dimensional version of the Wiener-Kolmogorov <span class="math notranslate nohighlight">\(m\)</span>-step ahead prediction formula.</p>
<p>We can use <a class="reference internal" href="#equation-eq-58">(59.26)</a>  to represent the linear least squares projection of
the vector <span class="math notranslate nohighlight">\(x\)</span> conditioned on the first <span class="math notranslate nohighlight">\(s\)</span> observations
<span class="math notranslate nohighlight">\([x_s, x_{s-1} \ldots, x_1]\)</span>.</p>
<p>We have</p>
<div class="math notranslate nohighlight" id="equation-eq-59">
<span class="eqno">(59.27)<a class="headerlink" href="#equation-eq-59" title="Permalink to this equation">¶</a></span>\[\begin{split}\mathbb{\hat E}[x \mid x_s, x_{s-1}, \ldots, x_1]
= L^{-1}
\left[
    \begin{matrix}
        I_s &amp; 0 \\
        0 &amp; 0_{(t-s)}
    \end{matrix}
\right] L x\end{split}\]</div>
<p>This formula will be convenient in representing the solution of control problems under uncertainty.</p>
<p>Equation <a class="reference internal" href="#equation-eq-55">(59.23)</a>  can be recognized as a finite dimensional version of a moving average representation.</p>
<p>Equation  <a class="reference internal" href="#equation-eq-54">(59.22)</a> can be viewed as a finite dimension version of an autoregressive representation.</p>
<p>Notice that even
if the <span class="math notranslate nohighlight">\(x_t\)</span> process is covariance stationary, so that <span class="math notranslate nohighlight">\(V\)</span>
is such that <span class="math notranslate nohighlight">\(V_{ij}\)</span> depends only on <span class="math notranslate nohighlight">\(\vert i-j\vert\)</span>, the
coefficients in the moving average representation are time-dependent,
there being a different moving average for each <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>If
<span class="math notranslate nohighlight">\(x_t\)</span> is a covariance stationary process, the last row of
<span class="math notranslate nohighlight">\(L^{-1}\)</span> converges to the coefficients in the Wold moving average
representation for <span class="math notranslate nohighlight">\(\{ x_t\}\)</span> as <span class="math notranslate nohighlight">\(T \rightarrow \infty\)</span>.</p>
<p>Further, if <span class="math notranslate nohighlight">\(x_t\)</span> is covariance stationary, for fixed <span class="math notranslate nohighlight">\(k\)</span>
and <span class="math notranslate nohighlight">\(j &gt; 0, \, L^{-1}_{T,T-j}\)</span> converges to
<span class="math notranslate nohighlight">\(L^{-1}_{T-k, T-k-j}\)</span> as <span class="math notranslate nohighlight">\(T \rightarrow \infty\)</span>.</p>
<p>That is,
the “bottom” rows of <span class="math notranslate nohighlight">\(L^{-1}\)</span> converge to each other and to the
Wold moving average coefficients as <span class="math notranslate nohighlight">\(T \rightarrow \infty\)</span>.</p>
<p>This last observation gives one simple and widely-used practical way of
forming a finite <span class="math notranslate nohighlight">\(T\)</span> approximation to a Wold moving average
representation.</p>
<p>First, form the covariance matrix
<span class="math notranslate nohighlight">\(\mathbb{E}xx^\prime = V\)</span>, then obtain the Cholesky decomposition
<span class="math notranslate nohighlight">\(L^{-1} L^{-1^\prime}\)</span> of <span class="math notranslate nohighlight">\(V\)</span>, which can be accomplished
quickly on a computer.</p>
<p>The last row of <span class="math notranslate nohighlight">\(L^{-1}\)</span> gives the approximate Wold moving average coefficients.</p>
<p>This method can readily be generalized to multivariate systems.</p>
</div>
</div>
<div class="section" id="combined-finite-dimensional-control-and-prediction">
<span id="fdcp"></span><h2><a class="toc-backref" href="#id22"><span class="section-number">59.4. </span>Combined Finite Dimensional Control and Prediction</a><a class="headerlink" href="#combined-finite-dimensional-control-and-prediction" title="Permalink to this headline">¶</a></h2>
<p>Consider the finite-dimensional control problem, maximize</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E} \, \sum^N_{t=0} \,
\left\{
     a_t y_t - {1 \over 2} h y^2_t - {1 \over 2} [d(L) y_t ]^2
\right\},\  \quad h &gt; 0
\]</div>
<p>where <span class="math notranslate nohighlight">\(d(L) = d_0 + d_1 L+ \ldots + d_m L^m\)</span>, <span class="math notranslate nohighlight">\(L\)</span> is the
lag operator, <span class="math notranslate nohighlight">\(\bar a = [ a_N, a_{N-1} \ldots, a_1, a_0]^\prime\)</span> a
random vector with mean zero and <span class="math notranslate nohighlight">\(\mathbb{E}\,\bar a \bar a^\prime = V\)</span>.</p>
<p>The variables <span class="math notranslate nohighlight">\(y_{-1}, \ldots, y_{-m}\)</span> are given.</p>
<p>Maximization is over choices of <span class="math notranslate nohighlight">\(y_0,
y_1 \ldots, y_N\)</span>, where <span class="math notranslate nohighlight">\(y_t\)</span> is required to be a linear function
of <span class="math notranslate nohighlight">\(\{y_{t-s-1}, t+m-1\geq 0;\ a_{t-s}, t\geq s\geq 0\}\)</span>.</p>
<p>We saw in the lecture <a class="reference internal" href="lu_tricks.html"><span class="doc">Classical Control with Linear Algebra</span></a>  that the solution of this problem under certainty could be represented in feedback-feedforward form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
U \bar y
   = L^{-1}\bar a + K
   \left[
     \begin{matrix}
         y_{-1}\\
         \vdots\\
         y_{-m}
     \end{matrix}
   \right]
\end{split}\]</div>
<p>for some <span class="math notranslate nohighlight">\((N+1)\times m\)</span> matrix <span class="math notranslate nohighlight">\(K\)</span>.</p>
<p>Using a version of formula <a class="reference internal" href="#equation-eq-58">(59.26)</a>, we can express <span class="math notranslate nohighlight">\(\mathbb{\hat E}[\bar a \mid a_s,\, a_{s-1}, \ldots, a_0 ]\)</span> as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbb{\hat E}
[ \bar a \mid a_s,\, a_{s-1}, \ldots, a_0]
= \tilde U^{-1}
\left[
    \begin{matrix}
        0 &amp; 0 \\
        0 &amp; I_{(s+1)}
    \end{matrix}
\right]
\tilde U \bar a
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(I_{(s + 1)}\)</span> is the <span class="math notranslate nohighlight">\((s+1) \times (s+1)\)</span> identity
matrix, and <span class="math notranslate nohighlight">\(V = \tilde U^{-1} \tilde U^{-1^{\prime}}\)</span>, where
<span class="math notranslate nohighlight">\(\tilde U\)</span> is the <em>upper</em> trangular Cholesky factor of the
covariance matrix <span class="math notranslate nohighlight">\(V\)</span>.</p>
<p>(We have reversed the time axis in dating the <span class="math notranslate nohighlight">\(a\)</span>’s relative to earlier)</p>
<p>The time axis can be reversed in representation <a class="reference internal" href="#equation-eq-59">(59.27)</a> by replacing <span class="math notranslate nohighlight">\(L\)</span> with <span class="math notranslate nohighlight">\(L^T\)</span>.</p>
<p>The optimal decision rule to use at time <span class="math notranslate nohighlight">\(0 \leq t \leq N\)</span> is then
given by the <span class="math notranslate nohighlight">\((N-t +1)^{\rm th}\)</span> row of</p>
<div class="math notranslate nohighlight">
\[\begin{split}
U \bar y = L^{-1} \tilde U^{-1}
    \left[
        \begin{matrix}
            0 &amp; 0 \\
            0 &amp; I_{(t+1)}
        \end{matrix}
    \right]
    \tilde U \bar a + K
    \left[
    \begin{matrix}
        y_{-1}\\
        \vdots\\
        y_{-m}
    \end{matrix}
    \right]
\end{split}\]</div>
</div>
<div class="section" id="exercises">
<h2><a class="toc-backref" href="#id23"><span class="section-number">59.5. </span>Exercises</a><a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<div class="section" id="exercise-1">
<h3><span class="section-number">59.5.1. </span>Exercise 1<a class="headerlink" href="#exercise-1" title="Permalink to this headline">¶</a></h3>
<p>Let <span class="math notranslate nohighlight">\(Y_t = (1 - 2 L ) u_t\)</span> where <span class="math notranslate nohighlight">\(u_t\)</span> is a mean zero
white noise with <span class="math notranslate nohighlight">\(\mathbb{E} u^2_t = 1\)</span>. Let</p>
<div class="math notranslate nohighlight">
\[
X_t = Y_t + \varepsilon_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon_t\)</span> is a serially uncorrelated white noise with
<span class="math notranslate nohighlight">\(\mathbb{E} \varepsilon^2_t = 9\)</span>, and <span class="math notranslate nohighlight">\(\mathbb{E} \varepsilon_t u_s = 0\)</span> for all
<span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>Find the Wold moving average representation for <span class="math notranslate nohighlight">\(X_t\)</span>.</p>
<p>Find a formula for the <span class="math notranslate nohighlight">\(A_{1j}\)</span>’s in</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E} \widehat X_{t+1} \mid X_t, X_{t-1}, \ldots = \sum^\infty_{j=0} A_{1j}
X_{t-j}
\]</div>
<p>Find a formula for the <span class="math notranslate nohighlight">\(A_{2j}\)</span>’s in</p>
<div class="math notranslate nohighlight">
\[
\mathbb{\hat E} X_{t+2} \mid X_t, X_{t-1}, \ldots = \sum^\infty_{j=0} A_{2j}
X_{t-j}
\]</div>
</div>
<div class="section" id="exercise-2">
<h3><span class="section-number">59.5.2. </span>Exercise 2<a class="headerlink" href="#exercise-2" title="Permalink to this headline">¶</a></h3>
<p>(Multivariable Prediction) Let <span class="math notranslate nohighlight">\(Y_t\)</span> be an <span class="math notranslate nohighlight">\((n\times 1)\)</span>
vector stochastic process with moving average representation</p>
<div class="math notranslate nohighlight">
\[
Y_t = D(L) U_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(D(L) = \sum^m_{j=0} D_j L^J, D_j\)</span> an <span class="math notranslate nohighlight">\(n \times n\)</span>
matrix, <span class="math notranslate nohighlight">\(U_t\)</span> an <span class="math notranslate nohighlight">\((n \times 1)\)</span> vector white noise with
:math: mathbb{E} U_t =0 for all <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E} U_t U_s' = 0\)</span> for all <span class="math notranslate nohighlight">\(s \neq t\)</span>,
and <span class="math notranslate nohighlight">\(\mathbb{E} U_t U_t' = I\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(\varepsilon_t\)</span> be an <span class="math notranslate nohighlight">\(n \times 1\)</span> vector white noise with mean <span class="math notranslate nohighlight">\(0\)</span> and contemporaneous covariance matrix <span class="math notranslate nohighlight">\(H\)</span>, where <span class="math notranslate nohighlight">\(H\)</span> is a positive definite matrix.</p>
<p>Let <span class="math notranslate nohighlight">\(X_t = Y_t +\varepsilon_t\)</span>.</p>
<p>Define the covariograms as <span class="math notranslate nohighlight">\(C_X
(\tau) = \mathbb{E} X_t X^\prime_{t-\tau}, C_Y (\tau) = \mathbb{E} Y_t Y^\prime_{t-\tau},
C_{YX} (\tau) = \mathbb{E} Y_t X^\prime_{t-\tau}\)</span>.</p>
<p>Then define the matrix
covariance generating function, as in <a class="reference internal" href="lu_tricks.html#equation-onetwenty">(58.21)</a>, only interpret all the
objects in <a class="reference internal" href="lu_tricks.html#equation-onetwenty">(58.21)</a> as matrices.</p>
<p>Show that the covariance generating functions are given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    g_y (z) &amp;= D (z) D (z^{-1})^\prime \\
    g_X (z) &amp;= D (z) D (z^{-1})^\prime + H \\
    g_{YX} (z) &amp;= D (z) D (z^{-1})^\prime
\end{aligned}
\end{split}\]</div>
<p>A factorization of <span class="math notranslate nohighlight">\(g_X (z)\)</span> can be found (see <span id="id16">[<a class="reference internal" href="../zreferences.html#id15">Roz67</a>]</span> or <span id="id17">[<a class="reference internal" href="../zreferences.html#id16">Whi83</a>]</span>) of the form</p>
<div class="math notranslate nohighlight">
\[
D (z) D (z^{-1})^\prime + H = C (z) C (z^{-1})^\prime, \quad C (z) =
\sum^m_{j=0} C_j z^j
\]</div>
<p>where the zeros of <span class="math notranslate nohighlight">\(\vert C(z)\vert\)</span> do not lie inside the unit
circle.</p>
<p>A vector Wold moving average representation of <span class="math notranslate nohighlight">\(X_t\)</span> is then</p>
<div class="math notranslate nohighlight">
\[
X_t = C(L) \eta_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\eta_t\)</span> is an <span class="math notranslate nohighlight">\((n\times 1)\)</span> vector white noise that
is “fundamental” for <span class="math notranslate nohighlight">\(X_t\)</span>.</p>
<p>That is, <span class="math notranslate nohighlight">\(X_t - \mathbb{\hat E}\left[X_t \mid X_{t-1}, X_{t-2}
\ldots\right] = C_0 \, \eta_t\)</span>.</p>
<p>The optimum predictor of <span class="math notranslate nohighlight">\(X_{t+j}\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\mathbb{\hat E} \left[X_{t+j} \mid X_t, X_{t-1}, \ldots\right]
 = \left[{C(L) \over L^j} \right]_+ \eta_t
\]</div>
<p>If <span class="math notranslate nohighlight">\(C(L)\)</span> is invertible, i.e., if the zeros of <span class="math notranslate nohighlight">\(\det\)</span>
<span class="math notranslate nohighlight">\(C(z)\)</span> lie strictly outside the unit circle, then this formula can
be written</p>
<div class="math notranslate nohighlight">
\[
\mathbb{\hat E} \left[X_{t+j} \mid X_t, X_{t-1}, \ldots\right]
    = \left[{C(L) \over L^J} \right]_+ C(L)^{-1}\, X_t
\]</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.6"
        },
        kernelOptions: {
            kernelName: "julia-1.6",
            path: "./time_series_models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.6'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            
            <div class="sidebar bd-sidebar inactive" id="site-navigation">

                <div class="sidebar__header">


                    Contents

                </div>

                <nav class="sidebar__nav" id="sidebar-nav" aria-label="Main navigation">
                    <p class="caption">
 <span class="caption-text">
  Getting Started with Julia
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/getting_started.html">
   1. Setting up Your Julia Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/julia_environment.html">
   2. Interacting with Julia
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/julia_by_example.html">
   3. Introductory Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/julia_essentials.html">
   4. Julia Essentials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/fundamental_types.html">
   5. Arrays, Tuples, Ranges, and Other Fundamental Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/introduction_to_types.html">
   6. Introduction to Types and Generic Programming
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Package Ecosystem
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/generic_programming.html">
   7. Generic Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/general_packages.html">
   8. General Purpose Packages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/data_statistical_packages.html">
   9. Data and Statistics Packages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/optimization_solver_packages.html">
   10. Solvers, Optimizers, and Automatic Differentiation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Software Engineering
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/tools_editors.html">
   11. Julia Tools and Editors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/version_control.html">
   12. Git, GitHub, and Version Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/testing.html">
   13. Packages, Testing, and Continuous Integration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/need_for_speed.html">
   14. The Need for Speed
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/linear_algebra.html">
   15. Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/orth_proj.html">
   16. Orthogonal Projections and Their Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/lln_clt.html">
   17. LLN and CLT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/linear_models.html">
   18. Linear State Space Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/finite_markov.html">
   19. Finite Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/stationary_densities.html">
   20. Continuous State Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/kalman.html">
   21. A First Look at the Kalman Filter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/numerical_linear_algebra.html">
   22. Numerical Linear Algebra and Factorizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools_and_techniques/iterative_methods_sparsity.html">
   23. Krylov Methods and Matrix Conditioning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamic Programming
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/short_path.html">
   24. Shortest Paths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/mccall_model.html">
   25. Job Search I: The McCall Search Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/mccall_model_with_separation.html">
   26. Job Search II: Search and Separation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/wald_friedman.html">
   27. A Problem that Stumped Milton Friedman
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/odu.html">
   28. Job Search III: Search with Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/career.html">
   29. Job Search IV: Modeling Career Choice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/jv.html">
   30. Job Search V: On-the-Job Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/optgrowth.html">
   31. Optimal Growth I: The Stochastic Optimal Growth Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/coleman_policy_iter.html">
   32. Optimal Growth II: Time Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/egm_policy_iter.html">
   33. Optimal Growth III: The Endogenous Grid Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/lqcontrol.html">
   34. LQ Dynamic Programming Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/perm_income.html">
   35. Optimal Savings I: The Permanent Income Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/perm_income_cons.html">
   36. Optimal Savings II: LQ Techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/smoothing.html">
   37. Consumption and Tax Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/ifp.html">
   38. Optimal Savings III: Occasionally Binding Constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/robustness.html">
   39. Robustness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/discrete_dp.html">
   40. Discrete State Dynamic Programming
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Modeling in Continuous Time
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../continuous_time/seir_model.html">
   41. Modeling COVID 19 with Differential Equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../continuous_time/covid_sde.html">
   42. Modeling Shocks in COVID 19 with Stochastic Differential Equations
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/schelling.html">
   43. Schelling’s Segregation Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/lake_model.html">
   44. A Lake Model of Employment and Unemployment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/rational_expectations.html">
   45. Rational Expectations Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/markov_perf.html">
   46. Markov Perfect Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/markov_asset.html">
   47. Asset Pricing I: Finite State Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/lucas_model.html">
   48. Asset Pricing II: The Lucas Asset Pricing Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/harrison_kreps.html">
   49. Asset Pricing III:  Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/uncertainty_traps.html">
   50. Uncertainty Traps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/aiyagari.html">
   51. The Aiyagari Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/arellano.html">
   52. Default Risk and Income Fluctuations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/matsuyama.html">
   53. Globalization and Cycles
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Time Series Models
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arma.html">
   54. Covariance Stationary Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estspec.html">
   55. Estimation of Spectra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="additive_functionals.html">
   56. Additive Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multiplicative_functionals.html">
   57. Multiplicative Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lu_tricks.html">
   58. Classical Control with Linear Algebra
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   59. Classical Filtering With Linear Algebra
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamic Programming Squared
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/dyn_stack.html">
   60. Dynamic Stackelberg Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/lqramsey.html">
   61. Optimal Taxation in an LQ Economy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/opt_tax_recur.html">
   62. Optimal Taxation with State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/amss.html">
   63. Optimal Taxation without State-Contingent Debt
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../about_lectures.html">
   64. About these Lectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../troubleshooting.html">
   65. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../zreferences.html">
   66. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../status.html">
   67. Lecture Status
  </a>
 </li>
</ul>

                </nav>

                <div class="sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="toolbar">

            <div class="toolbar__inner">

                <ul class="toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="../intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                    <!-- <li class="btn__search">
                        <form action="../search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off">
                            <i data-feather="search"></i>
                        </form>
                    </li> -->
                </ul>

                <ul class="toolbar__links">
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="_notebooks/time_series_models/classical_filtering.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li data-tippy-content="Launch Notebook" id="launchButton"><a href="https://mybinder.org/v2/gh/QuantEcon/lecture-julia.notebooks/master?urlpath=tree/time_series_models/classical_filtering.ipynb" target="_blank"><i data-feather="play-circle"></i></a></li>
                        <li data-tippy-content="Download PDF" onClick="window.print()"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-julia.myst/tree/master/lectures/time_series_models/classical_filtering.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="" download><p style="color: white;">Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title">QuantEcon Notebook Launcher</p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input" onchange="onChangeListener()">
                
                    <option value="https://mybinder.org/v2/gh/QuantEcon/lecture-julia.notebooks/master?urlpath=tree/time_series_models/classical_filtering.ipynb">BinderHub</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <!-- <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" onchange="onChangeListener()">
                <i class="fas fa-check-circle"></i>
            </li> -->
            </ul>
        </div>

    </div> <!-- .wrapper-->
  </body>
</html>