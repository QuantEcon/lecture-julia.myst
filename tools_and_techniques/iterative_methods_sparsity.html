
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>23. Krylov Methods and Matrix Conditioning &#8212; Quantitative Economics with Julia</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol']},
            tex: {
                packages: {'[+]': ['boldsymbol']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/quantecon-book-theme.857ff391aaabaeb8c161d2309c375fe6.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">


    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="../_static/quantecon-book-theme.76bf49d7bbc59738cdb03766fad654af.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://julia.quantecon.org/tools_and_techniques/iterative_methods_sparsity.html" />
    <link rel="shortcut icon" href="../_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="24. Shortest Paths" href="../dynamic_programming/short_path.html" />
    <link rel="prev" title="22. Numerical Linear Algebra and Factorizations" href="numerical_linear_algebra.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Jesse Perla &amp; Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Julia, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on quantitative economic modeling, designed and written by Jesse Perla, Thomas J. Sargent and John Stachurski. The language instruction is Julia. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Krylov Methods and Matrix Conditioning"/>
<meta name="twitter:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Jesse Perla, Thomas J. Sargent and John Stachurski. The language instruction is Julia.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Krylov Methods and Matrix Conditioning" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://julia.quantecon.org/tools_and_techniques/iterative_methods_sparsity.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Jesse Perla, Thomas J. Sargent and John Stachurski. The language instruction is Julia." />
<meta property="og:site_name" content="Quantitative Economics with Julia" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="wrapper">

        <div class="main">

            <div class="page" id=tools_and_techniques/iterative_methods_sparsity>

                <div class="page__toc">

                    <div class="inner">

                        
                        <div class="page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   23.1. Overview
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#applications">
     23.1.1. Applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ill-conditioned-matrices">
   23.2. Ill-Conditioned Matrices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#condition-number">
     23.2.1. Condition Number
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#condition-numbers-and-matrix-operations">
     23.2.2. Condition Numbers and Matrix Operations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-a-monomial-basis-is-a-bad-idea">
     23.2.3. Why a Monomial Basis Is a Bad Idea
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#aside-on-runge-s-phenomenon">
       23.2.3.1. Aside on Runge’s Phenomenon
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-an-orthogonal-polynomial-basis">
       23.2.3.2. Using an Orthogonal Polynomial Basis
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lessons-for-approximation-and-interpolation">
       23.2.3.3. Lessons for Approximation and Interpolation
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stationary-iterative-algorithms-for-linear-systems">
   23.3. Stationary Iterative Algorithms for Linear Systems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stationary-methods">
     23.3.1. Stationary Methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jacobi-iteration">
     23.3.2. Jacobi Iteration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-stationary-methods">
     23.3.3. Other Stationary Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#krylov-methods">
   23.4. Krylov Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introduction-to-preconditioning">
     23.4.1. Introduction to Preconditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#methods-for-general-matrices">
     23.4.2. Methods for General Matrices
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matrix-free-methods">
     23.4.3. Matrix-Free Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iterative-methods-for-linear-least-squares">
   23.5. Iterative Methods for Linear Least Squares
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iterative-methods-for-eigensystems">
   23.6. Iterative Methods for Eigensystems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#krylov-methods-for-markov-chain-dynamics">
   23.7. Krylov Methods for Markov-Chain Dynamics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matrix-free-infinitesimal-generator">
     23.7.1. Matrix-free Infinitesimal Generator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solving-a-valuation-problem">
     23.7.2. Solving a Valuation Problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#markov-chain-steady-state-and-dynamics">
     23.7.3. Markov Chain Steady State and Dynamics
    </a>
   </li>
  </ul>
 </li>
</ul>

                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="../_static/qe-logo-large.png" class="logo" alt="logo"></a>
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="page__header">

                    <div class="page__header-copy">

                        <p class="page__header-heading"><a href="../intro.html">Quantitative Economics with Julia</a></p>

                        <p class="page__header-subheading">Krylov Methods and Matrix Conditioning</p>

                    </div>

                    <p class="page__header-authors">Jesse Perla & Thomas J. Sargent & John Stachurski</p>

                </div> <!-- .page__header -->



                
                <main class="page__content" role="main">
                    
                    <div>
                        
  <div id="qe-notebook-header" style="text-align:right;">
        <a href="https://quantecon.org/" title="quantecon.org">
                <img style="width:250px;display:inline;" src="https://assets.quantecon.org/img/qe-menubar-logo.svg" alt="QuantEcon">
        </a>
</div><div class="section" id="krylov-methods-and-matrix-conditioning">
<h1><a class="toc-backref" href="#id2"><span class="section-number">23. </span>Krylov Methods and Matrix Conditioning</a><a class="headerlink" href="#krylov-methods-and-matrix-conditioning" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#krylov-methods-and-matrix-conditioning" id="id2">Krylov Methods and Matrix Conditioning</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id3">Overview</a></p></li>
<li><p><a class="reference internal" href="#ill-conditioned-matrices" id="id4">Ill-Conditioned Matrices</a></p></li>
<li><p><a class="reference internal" href="#stationary-iterative-algorithms-for-linear-systems" id="id5">Stationary Iterative Algorithms for Linear Systems</a></p></li>
<li><p><a class="reference internal" href="#krylov-methods" id="id6">Krylov Methods</a></p></li>
<li><p><a class="reference internal" href="#iterative-methods-for-linear-least-squares" id="id7">Iterative Methods for Linear Least Squares</a></p></li>
<li><p><a class="reference internal" href="#iterative-methods-for-eigensystems" id="id8">Iterative Methods for Eigensystems</a></p></li>
<li><p><a class="reference internal" href="#krylov-methods-for-markov-chain-dynamics" id="id9">Krylov Methods for Markov-Chain Dynamics</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id3"><span class="section-number">23.1. </span>Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This lecture takes the structure of <a class="reference internal" href="numerical_linear_algebra.html"><span class="doc">numerical methods for linear algebra</span></a> and builds further
toward working with large, sparse matrices.  In the process, we will examine foundational numerical analysis such as
ill-conditioned matrices.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">Statistics</span><span class="p">,</span> <span class="n">BenchmarkTools</span><span class="p">,</span> <span class="n">Random</span>
<span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">42</span><span class="p">);</span>  <span class="c"># seed random numbers for reproducibility</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="applications">
<h3><span class="section-number">23.1.1. </span>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h3>
<p>In this section, we will consider variations on classic problems</p>
<ol>
<li><p>Solving a linear system for a square <span class="math notranslate nohighlight">\(A\)</span> where we will maintain throughout that there is a unique solution to</p>
<div class="math notranslate nohighlight">
\[
   A x = b
   \]</div>
</li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Linear_least_squares">Linear least-squares</a> solution, for a rectangular <span class="math notranslate nohighlight">\(A\)</span></p>
<div class="math notranslate nohighlight">
\[
   \min_x \| Ax -b \|^2
   \]</div>
<p>From theory, we know that if <span class="math notranslate nohighlight">\(A\)</span> has linearly independent columns, then the solution is the <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_least_squares#Derivation_of_the_normal_equations">normal equation</a></p>
<div class="math notranslate nohighlight">
\[
   x = (A'A)^{-1}A'b
   \]</div>
</li>
<li><p>In the case of a square matrix <span class="math notranslate nohighlight">\(A\)</span>, the  eigenvalue problem is that of finding <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span> such that</p>
<div class="math notranslate nohighlight">
\[
   A x = \lambda x
   \]</div>
<p>For eigenvalue problems, keep in mind that you do not always require all of the <span class="math notranslate nohighlight">\(\lambda\)</span>, and sometimes the largest (or smallest) would be enough.  For example, calculating the spectral radius requires only the eigenvalue with maximum absolute value.</p>
</li>
</ol>
</div>
</div>
<div class="section" id="ill-conditioned-matrices">
<h2><a class="toc-backref" href="#id4"><span class="section-number">23.2. </span>Ill-Conditioned Matrices</a><a class="headerlink" href="#ill-conditioned-matrices" title="Permalink to this headline">¶</a></h2>
<p>An important consideration in numerical linear algebra, and iterative methods in general, is the <a class="reference external" href="https://en.wikipedia.org/wiki/Condition_number#Matrices">condition number</a>.</p>
<p>An ill-conditioned matrix is one where the basis eigenvectors are close to, but not exactly, collinear.  While this poses no problem on pen and paper,
or with infinite-precision numerical methods, it is important in practice, for two reasons:</p>
<ol class="simple">
<li><p>Ill-conditioned matrices introduce numerical errors roughly in proportion to the base-10 log of the condition number.</p></li>
<li><p>The convergence speed of many iterative methods is based on the spectral properties of the matrices (e.g., the basis formed by the eigenvectors), and hence ill-conditioned systems can converge slowly.</p></li>
</ol>
<p>The solutions to these problems are to</p>
<ul class="simple">
<li><p>be careful with operations which introduce error based on the condition number (e.g., matrix inversions when the condition number is high)</p></li>
<li><p>choose, where possible, alternative representations which have less collinearity (e.g., an orthogonal polynomial basis rather than a monomial one)</p></li>
<li><p>use a preconditioner for iterative methods, which changes the spectral properties to increase convergence speed</p></li>
</ul>
<div class="section" id="condition-number">
<h3><span class="section-number">23.2.1. </span>Condition Number<a class="headerlink" href="#condition-number" title="Permalink to this headline">¶</a></h3>
<p>First, let’s define and explore the condition number <span class="math notranslate nohighlight">\(\kappa\)</span></p>
<div class="math notranslate nohighlight">
\[
\kappa(A) \equiv \|A\| \|A^{-1}\|
\]</div>
<p>where you can use the Cauchy–Schwarz inequality to show that <span class="math notranslate nohighlight">\(\kappa(A) \geq 1\)</span>.  While the condition number can be calculated with any norm, we will focus on the 2-norm.</p>
<p>First, a warning on calculations: Calculating the condition number for a matrix can be an expensive operation (as would calculating a determinant)
and should be thought of as roughly equivalent to doing an eigendecomposition.  So use it for detective work judiciously.</p>
<p>Let’s look at the condition number of a few matrices using the <code class="docutils literal notranslate"><span class="pre">cond</span></code> function (which allows a choice of the norm, but we’ll stick with the default 2-norm).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">I</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Here we see an example of the best-conditioned matrix, the identity matrix with its completely orthonormal basis, which has a condition number of 1.</p>
<p>On the other hand, notice that</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">ϵ</span> <span class="o">=</span> <span class="mf">1E-6</span>
<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="mf">0.0</span>
     <span class="mf">1.0</span> <span class="n">ϵ</span><span class="p">]</span>
<span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0000000000005004e6
</pre></div>
</div>
</div>
</div>
<p>has a condition number of order <code class="docutils literal notranslate"><span class="pre">10E6</span></code> - and hence (taking the base-10 log) you would expect to be introducing numerical errors of about 6 significant digits if you
are not careful.  For example, note that the inverse has both extremely large and extremely small negative numbers</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2×2 Matrix{Float64}:
  1.0    0.0
 -1.0e6  1.0e6
</pre></div>
</div>
</div>
</div>
<p>Since we know that the determinant of nearly collinear matrices is close to zero, this shows another symptom of poor conditioning</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0e-6
</pre></div>
</div>
</div>
</div>
<p>However, be careful since the determinant has a scale, while the condition number is dimensionless.  That is,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="nd">@show</span> <span class="n">det</span><span class="p">(</span><span class="mi">1000</span> <span class="o">*</span> <span class="n">A</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="mi">1000</span> <span class="o">*</span> <span class="n">A</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>det(1000A) = 1.0
cond(1000A) = 2.0000000000005001e6
</pre></div>
</div>
</div>
</div>
<p>In that case, the determinant of <code class="docutils literal notranslate"><span class="pre">A</span></code> is 1, while the condition number is unchanged.  This example also provides some
intuition that ill-conditioned matrices typically occur when a matrix has radically different scales (e.g., contains both <code class="docutils literal notranslate"><span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">1E-6</span></code>, or <code class="docutils literal notranslate"><span class="pre">1000</span></code> and <code class="docutils literal notranslate"><span class="pre">1E-3</span></code>).  This can occur frequently with both function approximation and linear least squares.</p>
</div>
<div class="section" id="condition-numbers-and-matrix-operations">
<h3><span class="section-number">23.2.2. </span>Condition Numbers and Matrix Operations<a class="headerlink" href="#condition-numbers-and-matrix-operations" title="Permalink to this headline">¶</a></h3>
<p>Multiplying a matrix by a constant does not change the condition number.  What about other operations?</p>
<p>For this example, we see that the inverse has the same condition number (though this will not always be the case).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cond(A) = 2.0000000000005004e6
cond(inv(A)) = 2.0000000002463197e6
</pre></div>
</div>
</div>
</div>
<p>The condition number of the product of two matrices can change radically and lead things to becoming
even more ill-conditioned.</p>
<p>This comes up frequently when calculating the product of a matrix and its transpose (e.g., forming the covariance matrix).  A classic example is the <a class="reference external" href="https://link.springer.com/article/10.1007%2FBF01386022">Läuchli matrix</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">lauchli</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">ϵ</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">&#39;</span><span class="p">;</span> <span class="n">ϵ</span> <span class="o">*</span> <span class="n">I</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span><span class="o">&#39;</span>
<span class="n">ϵ</span> <span class="o">=</span> <span class="mf">1E-8</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">lauchli</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">ϵ</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="kt">Matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3×4 Matrix{Float64}:
 1.0  1.0e-8  0.0     0.0
 1.0  0.0     1.0e-8  0.0
 1.0  0.0     0.0     1.0e-8
</pre></div>
</div>
</div>
</div>
<p>Note that the condition number increases substantially</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="n">L</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">L</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cond(L) = 1.732050807568878e8
cond(L&#39; * L) = 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.345191558726545e32
</pre></div>
</div>
</div>
</div>
<p>You can show that the analytic eigenvalues of this are <span class="math notranslate nohighlight">\(\{3 + \epsilon^2, \epsilon^2, \epsilon^2\}\)</span> but the poor conditioning
means it is difficult to distinguish these from <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>This comes up when conducting <a class="reference external" href="https://en.wikipedia.org/wiki/Principal_component_analysis#Singular_value_decomposition">Principal Component Analysis</a>, which
requires calculations of the eigenvalues of the covariance matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">sort</span><span class="p">(</span><span class="n">sqrt</span><span class="o">.</span><span class="p">(</span><span class="kt">Complex</span><span class="o">.</span><span class="p">(</span><span class="n">eigen</span><span class="p">(</span><span class="n">L</span><span class="o">*</span><span class="n">L</span><span class="o">&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)),</span> <span class="n">lt</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3-element Vector{ComplexF64}:
                   0.0 + 4.870456104375987e-9im
 4.2146848510894035e-8 + 0.0im
    1.7320508075688772 + 0.0im
</pre></div>
</div>
</div>
</div>
<p>Note that these are significantly different than the known analytic solution and, in particular, are difficult to distinguish from 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">sqrt</span><span class="o">.</span><span class="p">([</span><span class="mi">3</span> <span class="o">+</span> <span class="n">ϵ</span><span class="o">^</span><span class="mi">2</span><span class="p">,</span> <span class="n">ϵ</span><span class="o">^</span><span class="mi">2</span><span class="p">,</span> <span class="n">ϵ</span><span class="o">^</span><span class="mi">2</span><span class="p">])</span> <span class="o">|&gt;</span> <span class="n">sort</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3-element Vector{Float64}:
 1.0e-8
 1.0e-8
 1.7320508075688772
</pre></div>
</div>
</div>
</div>
<p>Alternatively, we could calculate these by taking the square of the singular values of <span class="math notranslate nohighlight">\(L\)</span> itself, which is much more accurate
and lets us clearly distinguish from zero</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">svd</span><span class="p">(</span><span class="n">L</span><span class="p">)</span><span class="o">.</span><span class="n">S</span>  <span class="o">|&gt;</span> <span class="n">sort</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3-element Vector{Float64}:
 9.999999999999997e-9
 1.0e-8
 1.7320508075688774
</pre></div>
</div>
</div>
</div>
<p>Similarly, we are better off calculating least squares directly rather than forming the normal equation (i.e., <span class="math notranslate nohighlight">\(A' A x = A' b\)</span>) ourselves</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">lauchli</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mf">1E-7</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">|&gt;</span> <span class="kt">Matrix</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x_sol_1</span> <span class="o">=</span> <span class="n">A</span> <span class="o">\</span> <span class="n">b</span>  <span class="c"># using a least-squares solver</span>
<span class="n">x_sol_2</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">A</span><span class="p">)</span> <span class="o">\</span> <span class="p">(</span><span class="n">A</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>  <span class="c"># forming the normal equation ourselves</span>
<span class="n">norm</span><span class="p">(</span><span class="n">x_sol_1</span> <span class="o">-</span> <span class="n">x_sol_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2502.05373776057
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="why-a-monomial-basis-is-a-bad-idea">
<h3><span class="section-number">23.2.3. </span>Why a Monomial Basis Is a Bad Idea<a class="headerlink" href="#why-a-monomial-basis-is-a-bad-idea" title="Permalink to this headline">¶</a></h3>
<p>A classic example of poorly conditioned matrices is using a monomial basis of a polynomial with interpolation.</p>
<p>Take a grid of points, <span class="math notranslate nohighlight">\(x_0, \ldots x_N\)</span> and values <span class="math notranslate nohighlight">\(y_0, \ldots y_N\)</span> where we want to calculate the
interpolating polynomial.</p>
<p>If we were to use the simplest, and most obvious, polynomial basis, then the calculation consists of finding the coefficients <span class="math notranslate nohighlight">\(c_1, \ldots c_n\)</span> where</p>
<div class="math notranslate nohighlight">
\[
P(x) = \sum_{i=0}^N c_i x^i
\]</div>
<p>To solve for the coefficients, we notice that this is a simple system of equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}
    \,y_0 = c_0 + c_1 x_0 + \ldots c_N x_0^N\\
    \,\ldots\\
    \,y_N = c_0 + c_1 x_N + \ldots c_N x_N^N
\end{array}
\end{split}\]</div>
<p>Or, stacking <span class="math notranslate nohighlight">\(c = \begin{bmatrix} c_0 &amp; \ldots &amp; c_N\end{bmatrix}, y = \begin{bmatrix} y_0 &amp; \ldots &amp; y_N\end{bmatrix}\)</span> and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A = \begin{bmatrix} 1 &amp; x_0 &amp; x_0^2 &amp; \ldots &amp;x_0^N\\
                    \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
                    1 &amp; x_N &amp; x_N^2 &amp; \ldots &amp; x_N^N
    \end{bmatrix}
\end{split}\]</div>
<p>We can then calculate the interpolating coefficients as the solution to</p>
<div class="math notranslate nohighlight">
\[
A c = y
\]</div>
<p>Implementing this for the interpolation of the <span class="math notranslate nohighlight">\(exp(x)\)</span> function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c"># generate some data to interpolate</span>

<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>
<span class="n">A_inv</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">A_inv</span> <span class="o">*</span> <span class="n">y</span>
<span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">c</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">Inf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.67435859516263e-10
</pre></div>
</div>
</div>
</div>
<p>The final step just checks the interpolation vs. the analytic function at the nodes.  Keep in mind that this should be very close to zero
since we are interpolating the function precisely at those nodes.
In our example, the Inf-norm (i.e., maximum difference) of the interpolation errors at the nodes is around <code class="docutils literal notranslate"><span class="pre">1E-9</span></code>, which
is reasonable for many problems.</p>
<p>But note that with <span class="math notranslate nohighlight">\(N=5\)</span> the condition number is already of order <code class="docutils literal notranslate"><span class="pre">1E6</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>564652.3214053963
</pre></div>
</div>
</div>
</div>
<p>What if we increase the degree of the polynomial with the hope of increasing the precision of the
interpolation?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c"># generate some data to interpolate</span>

<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>
<span class="n">A_inv</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">A_inv</span> <span class="o">*</span> <span class="n">y</span>
<span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">c</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">Inf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.159603122388944e-6
</pre></div>
</div>
</div>
</div>
<p>Here, we see that hoping to increase the precision between points by adding extra polynomial terms is backfiring.  By going to a 10th-order polynomial, we have
introduced an error of about <code class="docutils literal notranslate"><span class="pre">1E-5</span></code>, even at the interpolation points themselves.</p>
<p>This blows up quickly</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c"># generate some data to interpolate</span>

<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>
<span class="n">A_inv</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">A_inv</span> <span class="o">*</span> <span class="n">y</span>
<span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">c</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">Inf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>27826.246592740674
</pre></div>
</div>
</div>
</div>
<p>To see the source of the problem, note that the condition number is astronomical.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0386741019186427e24
</pre></div>
</div>
</div>
</div>
<p>At this point, you should be suspicious of the use of <code class="docutils literal notranslate"><span class="pre">inv(A)</span></code>, since we have considered solving
linear systems by taking the inverse as verboten.  Indeed, this made things much worse.  The
error drops dramatically if we solve it as a linear system</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">A</span> <span class="o">\</span> <span class="n">y</span>
<span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">c</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">Inf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.4097167877480388e-10
</pre></div>
</div>
</div>
</div>
<p>But an error of <code class="docutils literal notranslate"><span class="pre">1E-10</span></code> at the interpolating nodes themselves can be a problem in many applications, and if you increase <code class="docutils literal notranslate"><span class="pre">N</span></code>
then the error will become non-trivial eventually - even without taking the inverse.</p>
<p>The heart of the issue is that the monomial basis leads to a <a class="reference external" href="https://en.wikipedia.org/wiki/Vandermonde_matrix">Vandermonde matrix</a>, which
is especially ill-conditioned.</p>
<div class="section" id="aside-on-runge-s-phenomenon">
<h4><span class="section-number">23.2.3.1. </span>Aside on Runge’s Phenomenon<a class="headerlink" href="#aside-on-runge-s-phenomenon" title="Permalink to this headline">¶</a></h4>
<p>The monomial basis is also a good opportunity to look at a separate type of error due to <a class="reference external" href="https://en.wikipedia.org/wiki/Runge%27s_phenomenon">Runge’s Phenomenon</a>.    It is an important
issue in approximation theory, albeit not one driven by numerical approximation errors.</p>
<p>It turns out that using a uniform grid of points is, in general, the worst possible choice of interpolation nodes for a polynomial approximation.  This phenomenon can be seen with the interpolation of the seemingly innocuous Runge’s function, <span class="math notranslate nohighlight">\(g(x) = \frac{1}{1 + 25 x^2}\)</span>.</p>
<p>Let’s calculate the interpolation with a monomial basis to find the <span class="math notranslate nohighlight">\(c_i\)</span> such that</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{1 + 25 x^2} \approx \sum_{i=0}^N c_i x^i,\, \text{ for } -1 \leq x \leq 1
\]</div>
<p>First, interpolate with <span class="math notranslate nohighlight">\(N = 5\)</span> and avoid taking the inverse.  In that case, as long as we avoid taking an inverse, the numerical errors from the ill-conditioned matrix are manageable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Plots</span>


<span class="n">N_display</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">25</span><span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x_display</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N_display</span><span class="p">)</span>
<span class="n">y_display</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="p">(</span><span class="n">x_display</span><span class="p">)</span>

<span class="c"># interpolation</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">A_5</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>
<span class="n">c_5</span> <span class="o">=</span> <span class="n">A_5</span> <span class="o">\</span> <span class="n">y</span>

<span class="c"># use the coefficients to evaluate on x_display grid</span>
<span class="n">B_5</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x_display</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>   <span class="c"># calculate monomials for display grid</span>
<span class="n">y_5</span> <span class="o">=</span> <span class="n">B_5</span> <span class="o">*</span> <span class="n">c_5</span>  <span class="c"># calculates for each in x_display_grid</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x_display</span><span class="p">,</span> <span class="n">y_5</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;P_5(x)&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">x_display</span><span class="p">,</span> <span class="n">y_display</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;g(x)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/iterative_methods_sparsity_39_0.svg" src="../_images/iterative_methods_sparsity_39_0.svg" /></div>
</div>
<p>Note that while the function, <span class="math notranslate nohighlight">\(g(x)\)</span>, and the approximation with a 5th-order polynomial, <span class="math notranslate nohighlight">\(P_5(x)\)</span>, coincide at the 6 nodes, the
approximation has a great deal of error everywhere else.</p>
<p>The oscillations near the boundaries are the hallmarks of Runge’s Phenomenon.  You might guess that increasing the number
of grid points and the order of the polynomial will lead to better approximations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">A_9</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>
<span class="n">c_9</span> <span class="o">=</span> <span class="n">A_9</span> <span class="o">\</span> <span class="n">y</span>

<span class="c"># use the coefficients to evaluate on x_display grid</span>
<span class="n">B_9</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x_display</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>   <span class="c"># calculate monomials for display grid</span>
<span class="n">y_9</span> <span class="o">=</span> <span class="n">B_9</span> <span class="o">*</span> <span class="n">c_9</span>  <span class="c"># calculates for each in x_display_grid</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x_display</span><span class="p">,</span> <span class="n">y_9</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;P_9(x)&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">x_display</span><span class="p">,</span> <span class="n">y_display</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;g(x)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/iterative_methods_sparsity_41_0.svg" src="../_images/iterative_methods_sparsity_41_0.svg" /></div>
</div>
<p>While the approximation is better near <code class="docutils literal notranslate"><span class="pre">x=0</span></code>, the oscillations near the boundaries have become worse.  Adding on extra polynomial terms will not
globally increase the quality of the approximation.</p>
</div>
<div class="section" id="using-an-orthogonal-polynomial-basis">
<h4><span class="section-number">23.2.3.2. </span>Using an Orthogonal Polynomial Basis<a class="headerlink" href="#using-an-orthogonal-polynomial-basis" title="Permalink to this headline">¶</a></h4>
<p>We can minimize the numerical problems of an ill-conditioned basis matrix by choosing a different basis for the polynomials.</p>
<p>For example, <a class="reference external" href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> form an orthonormal basis under an appropriate inner product, and we can form precise high-order approximations, with very little numerical error</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">ApproxFun</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">Chebyshev</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="o">..</span><span class="mf">1.0</span><span class="p">)</span>  <span class="c"># form Chebyshev basis</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">points</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>  <span class="c"># chooses Chebyshev nodes</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">g_approx</span> <span class="o">=</span> <span class="n">Fun</span><span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">ApproxFun</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>  <span class="c"># transform fits the polynomial</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">g_approx</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">Inf</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">x_display</span><span class="p">,</span> <span class="n">g_approx</span><span class="o">.</span><span class="p">(</span><span class="n">x_display</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;P_10000(x)&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">x_display</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="p">(</span><span class="n">x_display</span><span class="p">),</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;g(x)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(g_approx.(x) - g.(x), Inf) = 4.440892098500626e-16
</pre></div>
</div>
<img alt="../_images/iterative_methods_sparsity_43_1.svg" src="../_images/iterative_methods_sparsity_43_1.svg" /></div>
</div>
<p>Besides the use of a different polynomial basis, we are approximating at different nodes (i.e., <a class="reference external" href="https://en.wikipedia.org/wiki/Chebyshev_nodes">Chebyshev nodes</a>).  Interpolation with Chebyshev polynomials at the Chebyshev nodes ends up minimizing (but not eliminating) Runge’s Phenomenon.</p>
</div>
<div class="section" id="lessons-for-approximation-and-interpolation">
<h4><span class="section-number">23.2.3.3. </span>Lessons for Approximation and Interpolation<a class="headerlink" href="#lessons-for-approximation-and-interpolation" title="Permalink to this headline">¶</a></h4>
<p>To summarize:</p>
<ol class="simple">
<li><p>Check the condition number on systems you suspect might be ill-conditioned (based on intuition of collinearity).</p></li>
<li><p>If you are working with ill-conditioned matrices, be especially careful not to take the inverse or multiply by the transpose.</p></li>
<li><p>Avoid a monomial polynomial basis.  Instead, use polynomials (e.g., Chebyshev or Lagrange) orthogonal under an appropriate inner product, or use a non-global basis such as cubic splines.</p></li>
<li><p>If possible, avoid using a uniform grid for interpolation and approximation, and choose nodes appropriate for the basis.</p></li>
</ol>
<p>However, sometimes you can’t avoid ill-conditioned matrices. This is especially common with discretization of PDEs and with linear least squares.</p>
</div>
</div>
</div>
<div class="section" id="stationary-iterative-algorithms-for-linear-systems">
<h2><a class="toc-backref" href="#id5"><span class="section-number">23.3. </span>Stationary Iterative Algorithms for Linear Systems</a><a class="headerlink" href="#stationary-iterative-algorithms-for-linear-systems" title="Permalink to this headline">¶</a></h2>
<p>As before, consider solving the equation</p>
<div class="math notranslate nohighlight">
\[
A x = b
\]</div>
<p>We will now
focus on cases where <span class="math notranslate nohighlight">\(A\)</span> is both massive (e.g., potentially millions of equations) and sparse, and sometimes ill-conditioned - but where there is always a unique solution.</p>
<p>While this may seem excessive, it occurs in practice due to the curse of dimensionality, discretizations
of PDEs, and when working with big data.</p>
<p>The methods in the previous lectures (e.g., factorization and approaches similar to Gaussian elimination) are called direct methods, and are able
in theory to converge to the exact solution in a finite number of steps while directly working with the matrix in memory.</p>
<p>Instead, iterative solutions start with a guess on a solution and iterate until convergence.  The benefit will be that
each iteration uses a lower-order operation (e.g., an <span class="math notranslate nohighlight">\(O(N^2)\)</span> matrix-vector product) which will make it possible to</p>
<ol class="simple">
<li><p>solve much larger systems, even if done less precisely.</p></li>
<li><p>define linear operators in terms of the matrix-vector products, rather than storing as a matrix.</p></li>
<li><p>get approximate solutions in progress prior to the completion of all algorithm steps, unlike the direct methods, which provide a solution only at the end.</p></li>
</ol>
<p>Of course, there is no free lunch, and the computational order of the iterations themselves would be comparable to the direct methods for a given level of tolerance (e.g., <span class="math notranslate nohighlight">\(O(N^3)\)</span> operations may be required to solve a dense unstructured system).</p>
<p>There are two types of iterative methods we will consider.  The first type is stationary methods, which iterate on a map in a way that’s similar to fixed-point problems, and the second type is <a class="reference external" href="https://en.wikipedia.org/wiki/Krylov_subspace">Krylov</a> methods, which iteratively solve using left-multiplications of the linear operator.</p>
<p>For our main examples, we will use the valuation of the continuous-time Markov chain from the <a class="reference internal" href="numerical_linear_algebra.html"><span class="doc">numerical methods for linear algebra</span></a> lecture.  That is, given a payoff vector <span class="math notranslate nohighlight">\(r\)</span>, a
discount rate <span class="math notranslate nohighlight">\(\rho\)</span>, and the infinitesimal generator of the Markov chain <span class="math notranslate nohighlight">\(Q\)</span>, solve the equation</p>
<div class="math notranslate nohighlight">
\[
\rho v = r + Q v
\]</div>
<p>With the sizes and types of matrices here, iterative methods are inappropriate in practice, but they will help us understand
the characteristics of convergence and how they relate to matrix conditioning.</p>
<div class="section" id="stationary-methods">
<h3><span class="section-number">23.3.1. </span>Stationary Methods<a class="headerlink" href="#stationary-methods" title="Permalink to this headline">¶</a></h3>
<p>First, we will solve with a direct method, which will give the solution to machine precision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">IterativeSolvers</span><span class="p">,</span> <span class="n">Statistics</span>
<span class="n">α</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">Tridiagonal</span><span class="p">(</span><span class="n">fill</span><span class="p">(</span><span class="n">α</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="n">α</span><span class="p">;</span> <span class="n">fill</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="n">α</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="p">);</span> <span class="o">-</span><span class="n">α</span><span class="p">],</span> <span class="n">fill</span><span class="p">(</span><span class="n">α</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">ρ</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">ρ</span> <span class="o">*</span> <span class="n">I</span> <span class="o">-</span> <span class="n">Q</span>
<span class="n">v_direct</span> <span class="o">=</span> <span class="n">A</span> <span class="o">\</span> <span class="n">r</span>
<span class="n">mean</span><span class="p">(</span><span class="n">v_direct</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100.00000000000004
</pre></div>
</div>
</div>
</div>
<p>Without proof, consider that given the discount rate of <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span>, this problem could be set up as a contraction for solving the Bellman
equation through methods such as value-function iteration.</p>
<p>The condition we will examine here is called <a class="reference external" href="https://en.wikipedia.org/wiki/Diagonally_dominant_matrix"><strong>diagonal dominance</strong></a>.</p>
<div class="math notranslate nohighlight">
\[
|A_{ii}| \geq \sum_{j\neq i} |A_{ij}| \quad\text{for all } i = 1\ldots N
\]</div>
<p>That is, in every row, the diagonal element is weakly greater in absolute value than the sum of all of the other elements in the row.  In cases
where it is strictly greater, we say that the matrix is strictly diagonally dominant.</p>
<p>With our example, given that <span class="math notranslate nohighlight">\(Q\)</span> is the infinitesimal generator of a Markov chain, we know that each row sums to 0, and hence
it is weakly diagonally dominant.</p>
<p>However, notice that when <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span>, and since the diagonal of <span class="math notranslate nohighlight">\(Q\)</span> is negative,  <span class="math notranslate nohighlight">\(A = ρ I - Q\)</span> makes the matrix strictly diagonally dominant.</p>
</div>
<div class="section" id="jacobi-iteration">
<h3><span class="section-number">23.3.2. </span>Jacobi Iteration<a class="headerlink" href="#jacobi-iteration" title="Permalink to this headline">¶</a></h3>
<p>For matrices that are <strong>strictly diagonally dominant</strong>, you can prove that a simple decomposition and iteration procedure
will converge.</p>
<p>To solve a system <span class="math notranslate nohighlight">\(A x = b\)</span>, split the matrix <span class="math notranslate nohighlight">\(A\)</span> into its diagonal and off-diagonal elements.  That is,</p>
<div class="math notranslate nohighlight">
\[
A = D + R
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
D = \begin{bmatrix} A_{11} &amp; 0 &amp; \ldots &amp; 0\\
                    0    &amp; A_{22} &amp; \ldots &amp; 0\\
                    \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
                    0 &amp; 0 &amp;  \ldots &amp; A_{NN}
    \end{bmatrix}
\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
R = \begin{bmatrix} 0 &amp; A_{12}  &amp; \ldots &amp; A_{1N} \\
                    A_{21}    &amp; 0 &amp; \ldots &amp; A_{2N} \\
                    \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
                    A_{N1}  &amp; A_{N2}  &amp;  \ldots &amp; 0
    \end{bmatrix}
\end{split}\]</div>
<p>Rearrange the <span class="math notranslate nohighlight">\((D + R)x = b\)</span> as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
D x &amp;= b - R x\\
x &amp;= D^{-1} (b - R x)
\end{align}
\end{split}\]</div>
<p>where, since <span class="math notranslate nohighlight">\(D\)</span> is diagonal, its inverse is trivial to calculate with <span class="math notranslate nohighlight">\(O(N)\)</span> complexity.</p>
<p>To solve, take an iteration <span class="math notranslate nohighlight">\(x^k\)</span>, starting from <span class="math notranslate nohighlight">\(x^0\)</span>, and then form a new guess with</p>
<div class="math notranslate nohighlight">
\[
x^{k+1} = D^{-1}(b - R x^k)
\]</div>
<p>The complexity here is <span class="math notranslate nohighlight">\(O(N^2)\)</span> for the matrix-vector product, and <span class="math notranslate nohighlight">\(O(N)\)</span> for the vector subtraction and division.</p>
<p>The package <a class="reference external" href="https://github.com/JuliaMath/IterativeSolvers.jl">IterativeSolvers.jl</a> package implements this method.</p>
<p>For our example, we start with a guess and solve for the value function and iterate</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">IterativeSolvers</span><span class="p">,</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">SparseArrays</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">jacobi!</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">40</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_direct</span><span class="p">,</span> <span class="nb">Inf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(v - v_direct, Inf) = 0.022858373200932647
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.022858373200932647
</pre></div>
</div>
</div>
</div>
<p>With this, after 40 iterations we see that the error is in the order of <code class="docutils literal notranslate"><span class="pre">1E-2</span></code></p>
</div>
<div class="section" id="other-stationary-methods">
<h3><span class="section-number">23.3.3. </span>Other Stationary Methods<a class="headerlink" href="#other-stationary-methods" title="Permalink to this headline">¶</a></h3>
<p>In practice, there are many methods that are better than Jacobi iteration. For example <a class="reference external" href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method">Gauss-Siedel</a>., which
splits the matrix <span class="math notranslate nohighlight">\(A = L + U\)</span> into a lower-triangular matrix <span class="math notranslate nohighlight">\(L\)</span> and an upper-triangular matrix <span class="math notranslate nohighlight">\(U\)</span> without the diagonal.</p>
<p>The iteration becomes</p>
<div class="math notranslate nohighlight">
\[
L x^{k+1} = b - U x^k
\]</div>
<p>In that case, since the <span class="math notranslate nohighlight">\(L\)</span> matrix is triangular, the system can be solved in <span class="math notranslate nohighlight">\(O(N^2)\)</span> operations after <span class="math notranslate nohighlight">\(b - U x^k\)</span> is formed</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">gauss_seidel!</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">40</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_direct</span><span class="p">,</span> <span class="nb">Inf</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(v - v_direct, Inf) = 1.5616376089155892e-5
</pre></div>
</div>
</div>
</div>
<p>The accuracy increases substantially. After 40 iterations, we see that the error is of the order of <code class="docutils literal notranslate"><span class="pre">1E-5</span></code></p>
<p>Another example is <a class="reference external" href="https://en.wikipedia.org/wiki/Successive_over-relaxation">Successive Over-relaxation (SOR)</a>, which takes a relaxation parameter <span class="math notranslate nohighlight">\(\omega &gt; 1\)</span> and decomposes the matrix as <span class="math notranslate nohighlight">\(A = L + D + U\)</span>, where <span class="math notranslate nohighlight">\(L, U\)</span> are strictly upper- and lower-diagonal matrices and <span class="math notranslate nohighlight">\(D\)</span> is diagonal.</p>
<p>Decompose the <span class="math notranslate nohighlight">\(A\)</span> matrix, multiply the system by <span class="math notranslate nohighlight">\(\omega\)</span>, and rearrange to find</p>
<div class="math notranslate nohighlight">
\[
(D + \omega L) x^{k+1} = \omega b - \left(\omega U +(\omega - 1)D \right)x^k
\]</div>
<p>In that case, <span class="math notranslate nohighlight">\(D + \omega L\)</span> is a triangular matrix, and hence the linear solution is <span class="math notranslate nohighlight">\(O(N^2)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">sor!</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">40</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_direct</span><span class="p">,</span> <span class="nb">Inf</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(v - v_direct, Inf) = 3.745356593753968e-7
</pre></div>
</div>
</div>
</div>
<p>The accuracy is now <code class="docutils literal notranslate"><span class="pre">1E-7</span></code>.  If we change the parameter to <span class="math notranslate nohighlight">\(\omega = 1.2\)</span>, the accuracy further increases to <code class="docutils literal notranslate"><span class="pre">1E-9</span></code>.</p>
<p>This technique is common with iterative methods:  Frequently, adding a damping or a relaxation parameter will counterintuitively speed up the convergence process.</p>
<p><strong>Note:</strong> The stationary iterative methods are not always used directly, but are sometimes used as a “smoothing” step (e.g., running 5-10 times) prior to using other Krylov methods.</p>
</div>
</div>
<div class="section" id="krylov-methods">
<h2><a class="toc-backref" href="#id6"><span class="section-number">23.4. </span>Krylov Methods</a><a class="headerlink" href="#krylov-methods" title="Permalink to this headline">¶</a></h2>
<p>A more commonly used set of iterative methods is based on <a class="reference external" href="https://en.wikipedia.org/wiki/Krylov_subspace">Krylov subspaces</a>, which involve iterating the <span class="math notranslate nohighlight">\(A^k x\)</span> matrix-vector product, and orthogonalizing to ensure that the resulting iteration is not too collinear.</p>
<p>The prototypical Krylov method is <a class="reference external" href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Conjugate Gradient</a>, which requires the <span class="math notranslate nohighlight">\(A\)</span> matrix to be
symmetric and positive definite.</p>
<p>Solving an example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sprand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>   <span class="c"># 10 percent non-zeros</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">A</span><span class="o">&#39;</span>  <span class="c"># easy way to generate a symmetric positive-definite matrix</span>
<span class="nd">@show</span> <span class="n">isposdef</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">x_direct</span> <span class="o">=</span> <span class="n">A</span> <span class="o">\</span> <span class="n">b</span>  <span class="c"># sparse direct solver more appropriate here</span>
<span class="n">cond</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">A</span><span class="o">&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>isposdef(A) = true
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.5791585364800934e10
</pre></div>
</div>
</div>
</div>
<p>Notice that the condition numbers tend to be large for large random matrices.</p>
<p>Solving this system with the conjugate gradient method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">cg!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">sol</span><span class="p">[</span><span class="k">end</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 174 iterations.
</pre></div>
</div>
</div>
</div>
<div class="section" id="introduction-to-preconditioning">
<h3><span class="section-number">23.4.1. </span>Introduction to Preconditioning<a class="headerlink" href="#introduction-to-preconditioning" title="Permalink to this headline">¶</a></h3>
<p>If you tell a numerical analyst that you are using direct methods, their first question may be, “which factorization?” But if you tell them you
are using an iterative method, they may ask “which preconditioner?”.</p>
<p>As discussed at the beginning of the lecture, the spectral properties of matrices determine the rate of convergence
of iterative methods. In particular, ill-conditioned matrices can converge slowly with iterative methods, for the same
reasons that naive value-function iteration will converge slowly if the discount rate is close to <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<p>Preconditioning solves this problem by adjusting the spectral properties of the matrix, at the cost of some extra computational
operations.</p>
<p>To see an example of a right-preconditioner, consider a matrix <span class="math notranslate nohighlight">\(P\)</span> which has a convenient and numerically stable inverse.  Then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
A x &amp;= b\\
A P^{-1} P x &amp;= b\\
A P^{-1} y &amp;= b\\
P x &amp;= y
\end{align}
\end{split}\]</div>
<p>That is, solve <span class="math notranslate nohighlight">\((A P^{-1})y = b\)</span> for <span class="math notranslate nohighlight">\(y\)</span>, and then solve <span class="math notranslate nohighlight">\(P x = y\)</span> for <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>There are all sorts of preconditioners, and they are specific to the particular problem at hand. The key features are that they have convenient (and lower-order!) ways to solve the
resulting system and they lower the condition number of the matrix.  To see this in action, we can look at a simple preconditioner.</p>
<p>The diagonal precondition is simply <code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">=</span> <span class="pre">Diagonal(A)</span></code>.  Depending on the matrix, this can change the condition number a little or a lot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">AP</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">inv</span><span class="p">(</span><span class="n">Diagonal</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
<span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
<span class="nd">@show</span> <span class="n">cond</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">AP</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cond(Matrix(A)) = 189186.6473381337
cond(Matrix(AP)) = 175174.59095330362
</pre></div>
</div>
</div>
</div>
<p>But it may or may not decrease the number of iterations</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Preconditioners</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">DiagonalPreconditioner</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">cg!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">sol</span><span class="p">[</span><span class="k">end</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 174 iterations.
</pre></div>
</div>
</div>
</div>
<p>Another classic preconditioner is the incomplete LU decomposition</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">IncompleteLU</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">ilu</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">τ</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">cg!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">Pl</span> <span class="o">=</span> <span class="n">P</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">sol</span><span class="p">[</span><span class="k">end</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 86 iterations.
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">τ</span></code> parameter determines the degree of the LU decomposition to conduct, providing a tradeoff between preconditioner and solve speed.</p>
<p>A good rule of thumb is that you should almost always be using a preconditioner with iterative methods, and you should experiment to find preconditioners that are appropriate for your problem.</p>
<p>Finally, naively trying another preconditioning approach (called <a class="reference external" href="https://en.wikipedia.org/wiki/Multigrid_method#Algebraic_MultiGrid_%28AMG%29">Algebraic Multigrid</a>) gives us a further drop in the number of iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="kt">AMGPreconditioner</span><span class="p">{</span><span class="kt">RugeStuben</span><span class="p">}(</span><span class="n">A</span><span class="p">)</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">cg!</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">Pl</span> <span class="o">=</span> <span class="n">P</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">sol</span><span class="p">[</span><span class="k">end</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 59 iterations.
</pre></div>
</div>
</div>
</div>
<p><em>Note:</em> Preconditioning is also available for stationary, iterative methods (see <a class="reference external" href="https://en.wikipedia.org/wiki/Preconditioner#Preconditioned_iterative_methods">this example</a>), but
is frequently not implemented since such methods are not often used for the complete solution.</p>
</div>
<div class="section" id="methods-for-general-matrices">
<h3><span class="section-number">23.4.2. </span>Methods for General Matrices<a class="headerlink" href="#methods-for-general-matrices" title="Permalink to this headline">¶</a></h3>
<p>There are many algorithms which exploit matrix structure (e.g., the conjugate gradient method for positive-definite matrices, and  MINRES for matrices that are only symmetric/Hermitian).</p>
<p>On the other hand, if there is no structure to a sparse matrix, then GMRES is a good approach.</p>
<p>To experiment with these methods, we will use our ill-conditioned interpolation problem with a monomial basis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">IterativeSolvers</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c"># generate some data to interpolate</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">([</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>  <span class="c"># initial guess required for iterative solutions</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;cond(A) = </span><span class="si">$</span><span class="p">(</span><span class="n">cond</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span><span class="s">, </span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s"> Norm error </span><span class="si">$</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="n">c</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="nb">Inf</span><span class="p">))</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cond(A) = 4.462833495403007e12, Converged after 11 iterations. Norm error 8.800998330116272e-8
</pre></div>
</div>
</div>
</div>
<p>That method converged in 11 iterations.  Now if we try it with an incomplete LU preconditioner, we see that it converges immediately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c"># generate some data to interpolate</span>
<span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_i</span><span class="o">^</span><span class="n">n</span> <span class="k">for</span> <span class="n">x_i</span> <span class="k">in</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span> <span class="k">in</span> <span class="mi">0</span><span class="o">:</span><span class="n">N</span><span class="p">]</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">ilu</span><span class="p">(</span><span class="n">sparse</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">τ</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>  <span class="c"># initial guess required for iterative solutions</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Pl</span> <span class="o">=</span> <span class="n">P</span><span class="p">,</span><span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s"> Norm error </span><span class="si">$</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="n">c</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="nb">Inf</span><span class="p">))</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 1 iterations. Norm error 4.5034175855107605e-7
</pre></div>
</div>
</div>
</div>
<p>With other preconditioners (e.g., <code class="docutils literal notranslate"><span class="pre">DiagonalPreconditioner</span></code>), we may save only one or two iterations.  Keep in mind,
however, to consider the cost of the preconditioning process in your problem.</p>
</div>
<div class="section" id="matrix-free-methods">
<h3><span class="section-number">23.4.3. </span>Matrix-Free Methods<a class="headerlink" href="#matrix-free-methods" title="Permalink to this headline">¶</a></h3>
<p>First, lets use a Krylov method to solve our simple valuation problem</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">α</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">Tridiagonal</span><span class="p">(</span><span class="n">fill</span><span class="p">(</span><span class="n">α</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="n">α</span><span class="p">;</span> <span class="n">fill</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="n">α</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="p">);</span> <span class="o">-</span><span class="n">α</span><span class="p">],</span> <span class="n">fill</span><span class="p">(</span><span class="n">α</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">ρ</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">ρ</span> <span class="o">*</span> <span class="n">I</span> <span class="o">-</span> <span class="n">Q</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span>
<span class="n">v_sol</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 20 iterations.
</pre></div>
</div>
</div>
</div>
<p>While the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix was important to be kept in memory for direct methods, Krylov methods such as GMRES are built on matrix-vector products, i.e., <span class="math notranslate nohighlight">\(A x\)</span> for iterations on the <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>This product can be written directly for a given <span class="math notranslate nohighlight">\(x\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A x = \begin{bmatrix} (\rho + \alpha) x_1 - \alpha x_2\\
                    - \alpha x_1 + (\rho + 2 \alpha) x_2 - \alpha x_3\\
                    \vdots\\
                    - \alpha x_{N-2} + (\rho + 2 \alpha) x_{N-1} - \alpha x_{N}\\
                    - \alpha x_{N-1} + (\rho + \alpha) x_N
    \end{bmatrix}
\end{split}\]</div>
<p>This can be implemented as a function (either in-place or out-of-place) which calculates <span class="math notranslate nohighlight">\(y = A x\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">A_mul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span> <span class="p">(</span><span class="n">ρ</span> <span class="o">+</span> <span class="n">α</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
             <span class="p">[</span><span class="o">-</span><span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">ρ</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">α</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">2</span><span class="o">:</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>  <span class="c"># comprehension</span>
             <span class="o">-</span> <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">ρ</span> <span class="o">+</span> <span class="n">α</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="p">]]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="n">A_mul</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c"># compare to matrix;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(A * x - A_mul(x)) = 0.0
</pre></div>
</div>
</div>
</div>
<p>The final line verifies that the <code class="docutils literal notranslate"><span class="pre">A_mul</span></code> function provides the same result as the matrix multiplication with our original <code class="docutils literal notranslate"><span class="pre">A</span></code> for a random vector.</p>
<p>In abstract mathematics, a finite-dimensional <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_map">linear operator</a> is a mapping <span class="math notranslate nohighlight">\(A : R^N \to R^N\)</span>
that satisfies a number of criteria such as <span class="math notranslate nohighlight">\(A (c_1 x_1 + c_2 x_2) = c_1 A x_1 + c_2 A x_2\)</span> for scalars <span class="math notranslate nohighlight">\(c_i\)</span> and vectors <span class="math notranslate nohighlight">\(x_i\)</span>.</p>
<p>Moving from abstract mathematics to <a class="reference internal" href="../more_julia/generic_programming.html"><span class="doc">generic programming</span></a>, we can think of a linear operator
as a map that satisfies a number of requirements (e.g., it has a left-multiply to apply the map <code class="docutils literal notranslate"><span class="pre">*</span></code>, an in-place left-multiply <code class="docutils literal notranslate"><span class="pre">mul!</span></code>, an associated <code class="docutils literal notranslate"><span class="pre">size</span></code>).  A Julia matrix
is just one possible implementation of the abstract concept of a linear operator.</p>
<p>Convenience wrappers can provide some of the boilerplate which turns the <code class="docutils literal notranslate"><span class="pre">A_mul</span></code> function into something that behaves like a matrix.  One
package is <a class="reference external" href="https://github.com/Jutho/LinearMaps.jl">LinearMaps.jl</a> and another is <a class="reference external" href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl">LinearOperators.jl</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">LinearMaps</span>
<span class="n">A_map</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">(</span><span class="n">A_mul</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>  <span class="c"># map uses the A_mul function</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100×100 LinearMaps.FunctionMap{Float64}(A_mul; ismutating=false, issymmetric=false, ishermitian=false, isposdef=false)
</pre></div>
</div>
</div>
</div>
<p>Now, with the <code class="docutils literal notranslate"><span class="pre">A_map</span></code> object, we can fulfill many of the operations we would expect from a matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">A_map</span> <span class="o">*</span> <span class="n">x</span>  <span class="o">-</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">similar</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">mul!</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">A_map</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="c"># in-place multiplication</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">size</span><span class="p">(</span><span class="n">A_map</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">A_map</span><span class="p">)</span> <span class="o">-</span> <span class="n">A</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">nnz</span><span class="p">(</span><span class="n">sparse</span><span class="p">(</span><span class="n">A_map</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(A_map * x - A * x) = 0.0
norm(y - A * x) = 0.0
size(A_map) = (100, 100)
norm(Matrix(A_map) - A) = 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
nnz(sparse(A_map)) = 298
</pre></div>
</div>
</div>
</div>
<p><strong>Note:</strong>  In the case of <code class="docutils literal notranslate"><span class="pre">sparse(A_map)</span></code> and <code class="docutils literal notranslate"><span class="pre">Matrix(A_map)</span></code>, the code is using the left-multiplication operator with <code class="docutils literal notranslate"><span class="pre">N</span></code> standard basis vectors to construct
the full matrix.  This should be used only for testing purposes.</p>
<p>But notice that as the linear operator does not have indexing operations, it is not an array or a matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">typeof</span><span class="p">(</span><span class="n">A_map</span><span class="p">)</span> <span class="o">&lt;:</span> <span class="kt">AbstractArray</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>false
</pre></div>
</div>
</div>
</div>
<p>As long as algorithms using linear operators are written generically (e.g., using the matrix-vector <code class="docutils literal notranslate"><span class="pre">*</span></code> or <code class="docutils literal notranslate"><span class="pre">mul!</span></code> functionss) and the types of functions are not
unnecessarily constrained to be <code class="docutils literal notranslate"><span class="pre">Matrix</span></code> or <code class="docutils literal notranslate"><span class="pre">AbstractArray</span></code> when it isn’t strictly necessary, then the <code class="docutils literal notranslate"><span class="pre">A_map</span></code> type can work in places which would otherwise require a matrix.</p>
<p>For example, the Krylov methods in <code class="docutils literal notranslate"><span class="pre">IterativeSolvers.jl</span></code> are written for generic left-multiplication</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">gmres</span><span class="p">(</span><span class="n">A_map</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>  <span class="c"># Krylov method using the matrix-free type</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 20 iterations.
</pre></div>
</div>
</div>
</div>
<p>These methods are typically not competitive with sparse, direct methods unless the problems become very large.  In that case,
we often want to work with pre-allocated vectors.  Instead of using <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">*</span> <span class="pre">x</span></code> for matrix-vector products,
we would use the in-place <code class="docutils literal notranslate"><span class="pre">mul!(y,</span> <span class="pre">A,</span> <span class="pre">x)</span></code> function.  The wrappers for linear operators all support in-place non-allocating versions for this purpose.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">A_mul!</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="c"># in-place version</span>
    <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ρ</span> <span class="o">+</span> <span class="n">α</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">2</span><span class="o">:</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">ρ</span> <span class="o">+</span> <span class="mi">2</span><span class="n">α</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span><span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">end</span>
    <span class="n">y</span><span class="p">[</span><span class="k">end</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">ρ</span> <span class="o">+</span> <span class="n">α</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">y</span>
<span class="k">end</span>
<span class="n">A_map_2</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">(</span><span class="n">A_mul!</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>  <span class="c"># ismutating == in-place</span>

<span class="n">v</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">A_map_2</span> <span class="o">*</span> <span class="n">v</span> <span class="o">-</span> <span class="n">A</span> <span class="o">*</span> <span class="n">v</span><span class="p">)</span>  <span class="c"># can still call with * and have it allocate</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">A_map_2</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span>  <span class="c"># in-place gmres</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(A_map_2 * v - A * v) = 0.0
Converged after 20 iterations.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Finally, keep in mind that the linear operators can compose, so that <span class="math notranslate nohighlight">\(A (c_1 x) + B (c_2 x) + x  = (c_1 A + c_2 B + I) x\)</span> is well defined for any linear operators - just as
it would be for matrices <span class="math notranslate nohighlight">\(A, B\)</span> and scalars <span class="math notranslate nohighlight">\(c_1, c_2\)</span>.</p>
<p>For example, take <span class="math notranslate nohighlight">\(2 A x + x = (2 A + I) x \equiv B x\)</span> as a new linear map,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">A_map</span>  <span class="o">+</span> <span class="n">I</span>  <span class="c"># composite linear operator</span>
<span class="n">B</span> <span class="o">*</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>  <span class="c"># left-multiply works with the composition</span>
<span class="n">typeof</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearMaps.LinearCombination{Float64, Tuple{LinearMaps.ScaledMap{Float64, Float64, LinearMaps.FunctionMap{Float64, typeof(A_mul), Nothing}}, LinearMaps.UniformScalingMap{Bool}}}
</pre></div>
</div>
</div>
</div>
<p>The wrappers, such as <code class="docutils literal notranslate"><span class="pre">LinearMap</span></code> wrappers, make this composition possible by keeping the composition
graph of the expression (i.e., <code class="docutils literal notranslate"><span class="pre">LinearCombination</span></code>) and implementing the left-multiply recursively using the rules of linearity.</p>
<p>Another example is to solve the <span class="math notranslate nohighlight">\(\rho v = r + Q v\)</span> equation for <span class="math notranslate nohighlight">\(v\)</span> with composition of matrix-free methods for <span class="math notranslate nohighlight">\(L\)</span>
rather than by creating the full <span class="math notranslate nohighlight">\(A = \rho - Q\)</span> operator, which we implemented as <code class="docutils literal notranslate"><span class="pre">A_mul</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Q_mul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span> <span class="o">-</span><span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>     <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
            <span class="p">[</span><span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">α</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">2</span><span class="o">:</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>  <span class="c"># comprehension</span>
            <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">α</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="p">];]</span>
<span class="n">Q_map</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">(</span><span class="n">Q_mul</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">A_composed</span> <span class="o">=</span> <span class="n">ρ</span> <span class="o">*</span> <span class="n">I</span> <span class="o">-</span> <span class="n">Q_map</span>   <span class="c"># map composition, performs no calculations</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">sparse</span><span class="p">(</span><span class="n">A_composed</span><span class="p">))</span>  <span class="c"># test produces the same matrix</span>
<span class="n">gmres</span><span class="p">(</span><span class="n">A_composed</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="nb">true</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(A - sparse(A_composed)) = 0.0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 20 iterations.
</pre></div>
</div>
</div>
</div>
<p>In this example, the left-multiply of the <code class="docutils literal notranslate"><span class="pre">A_composed</span></code> used by <code class="docutils literal notranslate"><span class="pre">gmres</span></code> uses the left-multiply of <code class="docutils literal notranslate"><span class="pre">Q_map</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> with the rules
of linearity.  The <code class="docutils literal notranslate"><span class="pre">A_composed</span> <span class="pre">=</span> <span class="pre">ρ</span> <span class="pre">*</span> <span class="pre">I</span> <span class="pre">-</span> <span class="pre">Q_map</span></code> operation simply creates the <code class="docutils literal notranslate"><span class="pre">LinearMaps.LinearCombination</span></code> type, and doesn’t perform any calculations on its own.</p>
</div>
</div>
<div class="section" id="iterative-methods-for-linear-least-squares">
<h2><a class="toc-backref" href="#id7"><span class="section-number">23.5. </span>Iterative Methods for Linear Least Squares</a><a class="headerlink" href="#iterative-methods-for-linear-least-squares" title="Permalink to this headline">¶</a></h2>
<p>In theory, the solution to the least-squares problem, <span class="math notranslate nohighlight">\(\min_x \| Ax -b \|^2\)</span>, is simply the solution to the normal equations <span class="math notranslate nohighlight">\((A'A) x  = A'b\)</span>.</p>
<p>We saw, however, that in practice, direct methods use a QR decomposition - in part because an ill-conditioned matrix <span class="math notranslate nohighlight">\(A\)</span> becomes even worse when <span class="math notranslate nohighlight">\(A' A\)</span> is formed.</p>
<p>For large problems, we can also consider Krylov methods for solving the linear least-squares problem.  One formulation is the <a class="reference external" href="https://stanford.edu/group/SOL/software/lsmr/LSMR-SISC-2011.pdf">LSMR</a> algorithm,
which can solve the regularized</p>
<div class="math notranslate nohighlight">
\[
\min_x \| Ax -b \|^2 + \| \lambda x\|^2
\]</div>
<p>The purpose of the <span class="math notranslate nohighlight">\(\lambda \geq 0\)</span> parameter is to dampen the iteration process and/or regularize the solution.  This isn’t required, but can help convergence for ill-conditioned matrices <span class="math notranslate nohighlight">\(A\)</span>.  With the
damping parameter, the normalized equations would become <span class="math notranslate nohighlight">\((A'A + \lambda^2 I) x  = A'b\)</span>.</p>
<p>We can compare solving the least-squares problem with LSMR and direct methods</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">M</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">σ</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">β</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
<span class="c"># simulate data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sprand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">β</span> <span class="o">+</span> <span class="n">σ</span> <span class="o">*</span> <span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">β_direct</span> <span class="o">=</span> <span class="n">X</span> <span class="o">\</span> <span class="n">y</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">lsmr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="n">β_lsmr</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">β_direct</span> <span class="o">-</span> <span class="n">β_lsmr</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(β_direct - β_lsmr) = 9.144972747723753e-6
Converged after 14 iterations.
</pre></div>
</div>
</div>
</div>
<p>Note that rather than forming this version of the normal equations, the LSMR algorithm uses the <span class="math notranslate nohighlight">\(A x\)</span> and <span class="math notranslate nohighlight">\(A' y\)</span> (i.e., the matrix-vector product and the matrix-transpose vector product) to implement an iterative
solution.  Unlike the previous versions, the left-multiply is insufficient since the least squares also deals with the transpose of the operator.  For this reason, in order to use
matrix-free methods, we need to define the <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">*</span> <span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">transpose(A)</span> <span class="pre">*</span> <span class="pre">y</span></code> functions separately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Could implement as matrix-free functions.</span>
<span class="n">X_func</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">u</span>  <span class="c"># matrix-vector product</span>
<span class="n">X_T_func</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">v</span>  <span class="c"># i.e., adjoint-vector product</span>

<span class="n">X_map</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">(</span><span class="n">X_func</span><span class="p">,</span> <span class="n">X_T_func</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">lsmr</span><span class="p">(</span><span class="n">X_map</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Converged after 14 iterations.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="iterative-methods-for-eigensystems">
<h2><a class="toc-backref" href="#id8"><span class="section-number">23.6. </span>Iterative Methods for Eigensystems</a><a class="headerlink" href="#iterative-methods-for-eigensystems" title="Permalink to this headline">¶</a></h2>
<p>When you use <code class="docutils literal notranslate"><span class="pre">eigen</span></code> on a dense matrix, it calculates an eigendecomposition and provides all the eigenvalues and eigenvectors.</p>
<p>While this is sometimes necessary, a spectral decomposition of a dense, unstructured matrix is one of the costliest <span class="math notranslate nohighlight">\(O(N^3)\)</span> operations (i.e., it has
one of the largest constants).  For large matrices, it is often infeasible.</p>
<p>Luckily, we frequently need only a few eigenvectors/eigenvalues (in some cases just one), which enables a different set of algorithms.</p>
<p>For example, in the case of a discrete-time Markov chain, in order to find the stationary distribution, we are looking for the
eigenvector associated with the eigenvalue 1.  As usual, a little linear algebra goes a long way.</p>
<p>From the <a class="reference external" href="https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem#Stochastic_matrices">Perron-Frobenius theorem</a>, the largest eigenvalue of an irreducible stochastic matrix is 1 - the same eigenvalue we are looking for.</p>
<p>Iterative methods for solving eigensystems allow targeting the smallest magnitude, the largest magnitude, and many others.  The easiest library
to use is <a class="reference external" href="https://julialinearalgebra.github.io/Arpack.jl/latest/">Arpack.jl</a>.</p>
<p>As an example,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Arpack</span><span class="p">,</span> <span class="n">LinearAlgebra</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">Tridiagonal</span><span class="p">([</span><span class="n">fill</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="p">);</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">fill</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">;</span> <span class="n">fill</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="p">);])</span>
<span class="n">A_adjoint</span> <span class="o">=</span> <span class="n">A</span><span class="o">&#39;</span>

<span class="c"># Find 1 of the largest magnitude eigenvalue</span>
<span class="n">λ</span><span class="p">,</span> <span class="n">ϕ</span> <span class="o">=</span> <span class="n">eigs</span><span class="p">(</span><span class="n">A_adjoint</span><span class="p">,</span> <span class="n">nev</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="ss">:LM</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ϕ</span> <span class="o">=</span> <span class="n">real</span><span class="p">(</span><span class="n">ϕ</span><span class="p">)</span> <span class="o">./</span> <span class="n">sum</span><span class="p">(</span><span class="n">real</span><span class="p">(</span><span class="n">ϕ</span><span class="p">))</span>
<span class="nd">@show</span> <span class="n">λ</span>
<span class="nd">@show</span> <span class="n">mean</span><span class="p">(</span><span class="n">ϕ</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>λ = ComplexF64[1.0000000000000189 + 0.0im]
mean(ϕ) = 0.001
</pre></div>
</div>
</div>
</div>
<p>Indeed, the <code class="docutils literal notranslate"><span class="pre">λ</span></code> is equal to <code class="docutils literal notranslate"><span class="pre">1</span></code>.  If we choose <code class="docutils literal notranslate"><span class="pre">nev</span> <span class="pre">=</span> <span class="pre">2</span></code>, it will provide the eigenpairs with the two eigenvalues of largest absolute value.</p>
<p><em>Hint</em>: If you get errors using <code class="docutils literal notranslate"><span class="pre">Arpack</span></code>, increase the <code class="docutils literal notranslate"><span class="pre">maxiter</span></code> parameter for your problems.</p>
<p>Iterative methods for eigensystems rely on matrix-vector products rather than decompositions, and are amenable to matrix-free approaches.  For example,
take the Markov chain for a simple counting process:</p>
<ol class="simple">
<li><p>The count starts at <span class="math notranslate nohighlight">\(1\)</span> and has a maximum of <span class="math notranslate nohighlight">\(N\)</span>.</p></li>
<li><p>With probability <span class="math notranslate nohighlight">\(\theta \geq 0\)</span>, an existing count is lost with probability <span class="math notranslate nohighlight">\(\zeta \geq 0\)</span> such that <span class="math notranslate nohighlight">\(\theta + \zeta \leq 1\)</span>.</p></li>
<li><p>If the count is at <span class="math notranslate nohighlight">\(1\)</span>, then the only transition is to add a count with probability <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>If the current count is <span class="math notranslate nohighlight">\(N\)</span>, then the only transition is to lose the count with probability <span class="math notranslate nohighlight">\(\zeta\)</span>.</p></li>
</ol>
<p>First, finding the transition matrix <span class="math notranslate nohighlight">\(P\)</span> and its adjoint directly as a check</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">θ</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">ζ</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">Tridiagonal</span><span class="p">(</span><span class="n">fill</span><span class="p">(</span><span class="n">ζ</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="n">θ</span><span class="p">;</span> <span class="n">fill</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">θ</span><span class="o">-</span><span class="n">ζ</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="p">);</span> <span class="mi">1</span><span class="o">-</span><span class="n">ζ</span><span class="p">],</span> <span class="n">fill</span><span class="p">(</span><span class="n">θ</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">P</span><span class="o">&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5×5 Tridiagonal{Float64, Vector{Float64}}:
 0.9  0.05   ⋅     ⋅     ⋅ 
 0.1  0.85  0.05   ⋅     ⋅ 
  ⋅   0.1   0.85  0.05   ⋅ 
  ⋅    ⋅    0.1   0.85  0.05
  ⋅    ⋅     ⋅    0.1   0.95
</pre></div>
</div>
</div>
</div>
<p>Implementing the adjoint-vector product directly, and verifying that it gives the same matrix as the adjoint</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">P_adj_mul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">θ</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ζ</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
                <span class="p">[</span><span class="n">θ</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">θ</span><span class="o">-</span><span class="n">ζ</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">ζ</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">2</span><span class="o">:</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>  <span class="c"># comprehension</span>
            <span class="n">θ</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">ζ</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="k">end</span><span class="p">];]</span>
<span class="n">P_adj_map</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">(</span><span class="n">P_adj_mul</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">P</span><span class="o">&#39;</span> <span class="o">-</span> <span class="n">sparse</span><span class="p">(</span><span class="n">P_adj_map</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(P&#39; - sparse(P_adj_map)) = 0.0
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
</pre></div>
</div>
</div>
</div>
<p>Finally, solving for the stationary distribution using the matrix-free method (which could be verified against the decomposition approach of <span class="math notranslate nohighlight">\(P'\)</span>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">λ</span><span class="p">,</span> <span class="n">ϕ</span> <span class="o">=</span> <span class="n">eigs</span><span class="p">(</span><span class="n">P_adj_map</span><span class="p">,</span> <span class="n">nev</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="ss">:LM</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ϕ</span> <span class="o">=</span> <span class="n">real</span><span class="p">(</span><span class="n">ϕ</span><span class="p">)</span> <span class="o">./</span> <span class="n">sum</span><span class="p">(</span><span class="n">real</span><span class="p">(</span><span class="n">ϕ</span><span class="p">))</span>
<span class="nd">@show</span> <span class="n">λ</span>
<span class="nd">@show</span> <span class="n">ϕ</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>λ = ComplexF64[1.0 + 0.0im]
ϕ = 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.03225806451612657; 0.06451612903225695; 0.1290322580645172; 0.25806451612903425; 0.516129032258065]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5×1 Matrix{Float64}:
 0.03225806451612657
 0.06451612903225695
 0.1290322580645172
 0.25806451612903425
 0.516129032258065
</pre></div>
</div>
</div>
</div>
<p>Of course, for a problem this simple, the direct eigendecomposition will be significantly faster.  Use matrix-free iterative methods only for large systems where
you do not need all of the eigenvalues.</p>
</div>
<div class="section" id="krylov-methods-for-markov-chain-dynamics">
<h2><a class="toc-backref" href="#id9"><span class="section-number">23.7. </span>Krylov Methods for Markov-Chain Dynamics</a><a class="headerlink" href="#krylov-methods-for-markov-chain-dynamics" title="Permalink to this headline">¶</a></h2>
<p>This example applies the methods in this lecture to a large continuous-time Markov chain, and provides some practice working with arrays of arbitrary dimensions.</p>
<p>Consider a version of the Markov-chain dynamics in <span id="id1">[<a class="reference internal" href="../zreferences.html#id4">Per19</a>]</span>, where a firm has a discrete number of customers of different types.  To keep things as simple as possible, assume that there are <span class="math notranslate nohighlight">\(m=1, \ldots M\)</span> types of customers and that the firm may have <span class="math notranslate nohighlight">\(n = 1, \ldots N\)</span> customers of each type.</p>
<p>To set the notation, let <span class="math notranslate nohighlight">\(n_m \in \{1, \ldots N\}\)</span> be the number of customers of type <span class="math notranslate nohighlight">\(m\)</span>, so that the state of a firm is <span class="math notranslate nohighlight">\(\{n_1, \ldots n_m \ldots, n_M\}\)</span>.  The cardinality of possible states is then <span class="math notranslate nohighlight">\(\mathbf{N}\equiv N^M\)</span>, which can blow up quickly as the number of types increases.</p>
<p>The stochastic process is a simple counting/forgetting process, as follows:</p>
<ol class="simple">
<li><p>For every <span class="math notranslate nohighlight">\(1 \leq n_m(t) &lt; N\)</span>, there is a <span class="math notranslate nohighlight">\(\theta\)</span> intensity of arrival of a new customer, so that <span class="math notranslate nohighlight">\(n_m(t+\Delta) = n_m(t) + 1\)</span>.</p></li>
<li><p>For every <span class="math notranslate nohighlight">\(1 &lt; n_m(t) \leq N\)</span>, there is a <span class="math notranslate nohighlight">\(\zeta\)</span> intensity of losing a customer, so that <span class="math notranslate nohighlight">\(n_m(t+\Delta) = n_m(t) - 1\)</span>.</p></li>
</ol>
<div class="section" id="matrix-free-infinitesimal-generator">
<h3><span class="section-number">23.7.1. </span>Matrix-free Infinitesimal Generator<a class="headerlink" href="#matrix-free-infinitesimal-generator" title="Permalink to this headline">¶</a></h3>
<p>In order to define an intensity matrix <span class="math notranslate nohighlight">\(Q\)</span> of size <span class="math notranslate nohighlight">\(\mathbf{N}\times \mathcal{N}\)</span>, we need to choose a consistent ordering of the states.  But
before we enumerate them linearly, take a <span class="math notranslate nohighlight">\(v\in R^{\mathbf{N}}\)</span> interpreted as a multidimensional array and look at the left product of the linear operator <span class="math notranslate nohighlight">\(Q v \to R^{\mathbf{N}}\)</span>.</p>
<p>For example, if we were implementing the product at the row of <span class="math notranslate nohighlight">\(Q\)</span> corresponding to the <span class="math notranslate nohighlight">\((n_1, \ldots, n_M)\)</span> state, then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
    Q_{(n_1, \ldots n_M)} \cdot v &amp;=
\theta \sum_{m=1}^M (n_m &lt; N)  v(n_1, \ldots, n_m + 1, \ldots, n_M)\\
                                        &amp;+ \zeta \sum_{m=1}^M (1 &lt; n_m)  v(n_1, \ldots, n_m - 1, \ldots, n_M)\\
                                        &amp;-\left(\theta\, \text{Count}(n_m &lt; N) + \zeta\, \text{Count}( n_m &gt; 1)\right)v(n_1, \ldots, n_M)
\end{align}
\end{split}\]</div>
<p>Here:</p>
<ul class="simple">
<li><p>the first term includes all of the arrivals of new customers into the various <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p>the second term is the loss of a customer for the various <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p>the last term is the intensity of all exits from this state (i.e., counting the intensity of all other transitions, to ensure that the row will sum to <span class="math notranslate nohighlight">\(0\)</span>)</p></li>
</ul>
<p>In practice, rather than working with the <span class="math notranslate nohighlight">\(f\)</span> as a multidimensional type, we will need to enumerate the discrete states linearly, so that we can iterate <span class="math notranslate nohighlight">\(f\)</span> between <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{N}\)</span>.  An especially convenient
approach is to enumerate them in the same order as the <span class="math notranslate nohighlight">\(K\)</span>-dimensional Cartesian product of the <span class="math notranslate nohighlight">\(N\)</span> states in the multi-dimensional array above.</p>
<p>This can be done with the <code class="docutils literal notranslate"><span class="pre">CartesianIndices</span></code> function, which is used internally in Julia for the <code class="docutils literal notranslate"><span class="pre">eachindex</span></code> function.  For example,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">shape</span> <span class="o">=</span> <span class="kt">Tuple</span><span class="p">(</span><span class="n">fill</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="o">...</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">typeof</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ind</span> <span class="k">in</span> <span class="kt">CartesianIndices</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot;v</span><span class="si">$</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span><span class="p">)</span><span class="s"> = </span><span class="si">$</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span><span class="s">&quot;</span><span class="p">)</span>  <span class="c"># .I gets the tuple to display</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>typeof(v) = Array{Float64, 3}
v(1, 1, 1) = 0.639089412234831
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>v(2, 1, 1) = 0.4302368488000152
v(1, 2, 1) = 0.21490768283644002
v(2, 2, 1) = 0.7542051014748841
v(1, 1, 2) = 0.4330861190374067
v(2, 1, 2) = 0.07556766967902084
v(1, 2, 2) = 0.2143739072351467
v(2, 2, 2) = 0.43231874437572815
</pre></div>
</div>
</div>
</div>
<p>The added benefit of this approach is that it will be the most efficient way to iterate through vectors in the implementation.</p>
<p>For the counting process with arbitrary dimensions, we will frequently be incrementing or decrementing the <span class="math notranslate nohighlight">\(m\)</span> unit vectors of the <code class="docutils literal notranslate"><span class="pre">CartesianIndex</span></code> type with</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">e_m</span> <span class="o">=</span> <span class="p">[</span><span class="kt">CartesianIndex</span><span class="p">((</span><span class="mi">1</span><span class="o">:</span><span class="n">M</span> <span class="o">.==</span> <span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span><span class="o">...</span><span class="p">)</span>  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">M</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3-element Vector{CartesianIndex{3}}:
 CartesianIndex(1, 0, 0)
 CartesianIndex(0, 1, 0)
 CartesianIndex(0, 0, 1)
</pre></div>
</div>
</div>
</div>
<p>and then use the vector to increment.  For example, if the current count is <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">2,</span> <span class="pre">2)</span></code> and we want to add a count of <code class="docutils literal notranslate"><span class="pre">1</span></code> to the first index and remove a count
of <code class="docutils literal notranslate"><span class="pre">1</span></code> from the third index, then</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">ind</span> <span class="o">=</span> <span class="kt">CartesianIndex</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c"># example counts coming from CartesianIndices</span>
<span class="nd">@show</span> <span class="n">ind</span> <span class="o">+</span> <span class="n">e_m</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c"># increment the first index</span>
<span class="nd">@show</span> <span class="n">ind</span> <span class="o">-</span> <span class="n">e_m</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>  <span class="c"># decrement the third index</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ind + e_m[1] = CartesianIndex(2, 2, 2)
ind - e_m[3] = CartesianIndex(1, 2, 1)
</pre></div>
</div>
</div>
</div>
<p>This works, of course, because the <code class="docutils literal notranslate"><span class="pre">CartesianIndex</span></code> type is written to support efficient addition and subtraction.  Finally, to implement the operator, we need to count the indices in the states where increment and decrement occurs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="nd">@show</span> <span class="n">ind</span>
<span class="nd">@show</span> <span class="n">count</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span> <span class="o">.&gt;</span> <span class="mi">1</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">count</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span> <span class="o">.&lt;</span> <span class="n">N</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ind = CartesianIndex(1, 2, 2)
count(ind.I .&gt; 1) = 2
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count(ind.I .&lt; N) = 1
</pre></div>
</div>
</div>
</div>
<p>With this, we are now able to write the <span class="math notranslate nohighlight">\(Q\)</span> operator on the <span class="math notranslate nohighlight">\(f\)</span> vector, which is enumerated by the Cartesian indices.  First, collect the
parameters in a named tuple generator</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Parameters</span><span class="p">,</span> <span class="n">BenchmarkTools</span>
<span class="n">default_params</span> <span class="o">=</span> <span class="nd">@with_kw</span> <span class="p">(</span><span class="n">θ</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">ζ</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">ρ</span> <span class="o">=</span> <span class="mf">0.03</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
                           <span class="n">shape</span> <span class="o">=</span> <span class="kt">Tuple</span><span class="p">(</span><span class="n">fill</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)),</span>  <span class="c"># for reshaping vector to M-d array</span>
                           <span class="n">e_m</span> <span class="o">=</span> <span class="p">([</span><span class="kt">CartesianIndex</span><span class="p">((</span><span class="mi">1</span><span class="o">:</span><span class="n">M</span> <span class="o">.==</span> <span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span><span class="o">...</span><span class="p">)</span>  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">M</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>##NamedTuple_kw#260 (generic function with 2 methods)
</pre></div>
</div>
</div>
</div>
<p>Next, implement the in-place matrix-free product</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">Q_mul!</span><span class="p">(</span><span class="n">dv</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="nd">@unpack</span> <span class="n">θ</span><span class="p">,</span> <span class="n">ζ</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">e_m</span> <span class="o">=</span> <span class="n">p</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>  <span class="c"># now can access v, dv as M-dim arrays</span>
    <span class="n">dv</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">dv</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>

    <span class="nd">@inbounds</span> <span class="k">for</span> <span class="n">ind</span> <span class="k">in</span> <span class="kt">CartesianIndices</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">dv</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">m</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">M</span>
            <span class="n">n_m</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">m</span><span class="p">]</span>
            <span class="k">if</span><span class="p">(</span><span class="n">n_m</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span>
                <span class="n">dv</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">+=</span> <span class="n">θ</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="n">ind</span> <span class="o">+</span> <span class="n">e_m</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
            <span class="k">end</span>
            <span class="k">if</span><span class="p">(</span><span class="n">n_m</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">dv</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ζ</span> <span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">ind</span> <span class="o">-</span> <span class="n">e_m</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
            <span class="k">end</span>
        <span class="k">end</span>
        <span class="n">dv</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">θ</span> <span class="o">*</span> <span class="n">count</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span> <span class="o">.&lt;</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">ζ</span> <span class="o">*</span> <span class="n">count</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span> <span class="o">.&gt;</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">()</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">dv</span> <span class="o">=</span> <span class="n">similar</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">Q_mul!</span><span class="p">(</span><span class="o">$</span><span class="n">dv</span><span class="p">,</span> <span class="o">$</span><span class="n">v</span><span class="p">,</span> <span class="o">$</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  52.823 ms (0 allocations: 0 bytes)
</pre></div>
</div>
</div>
</div>
<p>From the output of the benchmarking, note that the implementation of the left-multiplication takes less than 100 milliseconds, and allocates little or no memory, even though the Markov chain has a million possible states (i.e., <span class="math notranslate nohighlight">\(N^M = 10^6\)</span>).</p>
</div>
<div class="section" id="solving-a-valuation-problem">
<h3><span class="section-number">23.7.2. </span>Solving a Valuation Problem<a class="headerlink" href="#solving-a-valuation-problem" title="Permalink to this headline">¶</a></h3>
<p>As before, we could use this Markov chain to solve a Bellman equation.  Assume that the firm discounts at rate <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span> and gets a flow payoff of a different <span class="math notranslate nohighlight">\(z_m\)</span> per
customer of type <span class="math notranslate nohighlight">\(m\)</span>.  For example, if the state of the firm is <span class="math notranslate nohighlight">\((n_1, n_2, n_3) = (2,3,2)\)</span>, then it gets <span class="math notranslate nohighlight">\(\begin{bmatrix}2 &amp; 3 &amp; 2\end{bmatrix} \cdot \begin{bmatrix}z_1&amp; z_2 &amp; z_3\end{bmatrix}\)</span> in flow profits.</p>
<p>Given this profit function, we can write the simple Bellman equation in our standard form of <span class="math notranslate nohighlight">\(\rho v = r + Q v\)</span>, defining the appropriate payoff <span class="math notranslate nohighlight">\(r\)</span>.  For example, if <span class="math notranslate nohighlight">\(z_m = m^2\)</span>, then</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">r_vec</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span>  <span class="c"># payoffs per type m</span>
    <span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">dot</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>  <span class="k">for</span> <span class="n">ind</span> <span class="k">in</span> <span class="kt">CartesianIndices</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">reshape</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">)</span>  <span class="c"># return as a vector</span>
<span class="k">end</span>
<span class="nd">@show</span> <span class="n">typeof</span><span class="p">(</span><span class="n">r_vec</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="n">r_vec</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>typeof(r_vec(p)) = Vector{Float64}
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>250.25
</pre></div>
</div>
</div>
</div>
<p>Note that the returned <span class="math notranslate nohighlight">\(r\)</span> is a vector, enumerated in the same order as the <span class="math notranslate nohighlight">\(n_m\)</span> states.</p>
<p>Since the ordering of <span class="math notranslate nohighlight">\(r\)</span> is consistent with that of <span class="math notranslate nohighlight">\(Q\)</span>, we can solve <span class="math notranslate nohighlight">\((\rho - Q) v = r\)</span> as a linear system.</p>
<p>Below, we create a linear operator and compare the algorithm for a few different iterative methods <a class="reference external" href="https://juliamath.github.io/IterativeSolvers.jl/dev/#What-method-should-I-use-for-linear-systems?-1">(GMRES, BiCGStab(l), IDR(s), etc.)</a> with a small problem
of only 10,000 possible states.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">df</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_mul!</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">ρ</span> <span class="o">*</span> <span class="n">I</span> <span class="o">-</span> <span class="n">Q</span>
<span class="n">A_sparse</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>  <span class="c"># expensive: use only in tests</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">r_vec</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="n">v_direct</span> <span class="o">=</span> <span class="n">A_sparse</span> <span class="o">\</span> <span class="n">r</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">zero</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

<span class="nd">@btime</span> <span class="o">$</span><span class="n">A_sparse</span> <span class="o">\</span> <span class="o">$</span><span class="n">r</span>  <span class="c"># direct</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">-</span> <span class="n">v_direct</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">iv</span><span class="p">,</span> <span class="o">$</span><span class="n">A</span><span class="p">,</span> <span class="o">$</span><span class="n">r</span><span class="p">)</span> <span class="n">setup</span> <span class="o">=</span> <span class="p">(</span><span class="n">iv</span> <span class="o">=</span> <span class="n">zero</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>

<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">bicgstabl</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">-</span> <span class="n">v_direct</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">bicgstabl!</span><span class="p">(</span><span class="n">iv</span><span class="p">,</span> <span class="o">$</span><span class="n">A</span><span class="p">,</span> <span class="o">$</span><span class="n">r</span><span class="p">)</span> <span class="n">setup</span> <span class="o">=</span> <span class="p">(</span><span class="n">iv</span> <span class="o">=</span> <span class="n">zero</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>

<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">idrs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">-</span> <span class="n">v_direct</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">idrs</span><span class="p">(</span><span class="o">$</span><span class="n">A</span><span class="p">,</span> <span class="o">$</span><span class="n">r</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  355.159 ms (75 allocations: 181.85 MiB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(gmres(A, r) - v_direct) = 2.3908379262155663e-5
  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.236 ms (76 allocations: 2.53 MiB)
norm(bicgstabl(A, r) - v_direct) = 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7.44132362371748e-6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  10.333 ms (244 allocations: 7.95 MiB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(idrs(A, r) - v_direct) = 4.872514988248361e-5
  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.745 ms (227 allocations: 3.30 MiB)
</pre></div>
</div>
</div>
</div>
<p>Here, we see that even if the <span class="math notranslate nohighlight">\(A\)</span> matrix has been created, the direct sparse solver (which uses a sparse LU or QR) is at least an order of magnitude slower and allocates over an order of magnitude more memory.  This is in addition to the allocation for the <code class="docutils literal notranslate"><span class="pre">A_sparse</span></code> matrix itself, which is not needed for iterative methods.</p>
<p>The different iterative methods have tradeoffs when it comes to accuracy, speed, convergence rate, memory requirements, and usefulness of preconditioning.  Going much above <span class="math notranslate nohighlight">\(\mathbf{N} = 10^4\)</span>, the direct methods quickly become infeasible.</p>
<p>Putting everything together to solving much larger systems with GMRES as our linear solvers</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">solve_bellman</span><span class="p">(</span><span class="n">p</span><span class="p">;</span> <span class="n">iv</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">))</span>
    <span class="nd">@unpack</span> <span class="n">ρ</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">p</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">df</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_mul!</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">N</span><span class="o">^</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">ρ</span> <span class="o">*</span> <span class="n">I</span> <span class="o">-</span> <span class="n">Q</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">r_vec</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="n">sol</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">iv</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="nb">false</span><span class="p">)</span>  <span class="c"># iterative solver, matrix-free</span>
    <span class="k">return</span> <span class="n">sol</span>
<span class="k">end</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">solve_bellman</span><span class="p">(</span><span class="o">$</span><span class="n">p</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  913.597 ms (82 allocations: 274.67 MiB)
</pre></div>
</div>
</div>
</div>
<p>This solves a value function with a Markov chain of a million states in a little over a second!  This general approach seems to scale roughly linearly.  For example, try <span class="math notranslate nohighlight">\(N=10, M=8\)</span>
to solve an equation with a Markov chain with 100 million possible states, which can be solved in about 3-4 minutes.  Above that order of magnitude, you may need to tinker with the linear solver parameters to ensure that you are not memory limited (e.g., change the <code class="docutils literal notranslate"><span class="pre">restart</span></code> parameter of GMRES).</p>
</div>
<div class="section" id="markov-chain-steady-state-and-dynamics">
<h3><span class="section-number">23.7.3. </span>Markov Chain Steady State and Dynamics<a class="headerlink" href="#markov-chain-steady-state-and-dynamics" title="Permalink to this headline">¶</a></h3>
<p>Recall that given an <span class="math notranslate nohighlight">\(N\)</span>-dimensional intensity matrix <span class="math notranslate nohighlight">\(Q\)</span> of a CTMC, the evolution of the pdf from an initial condition <span class="math notranslate nohighlight">\(\psi(0)\)</span> is the system of linear differential equations</p>
<div class="math notranslate nohighlight">
\[
\dot{\psi}(t) = Q^T \psi(t)
\]</div>
<p>If <span class="math notranslate nohighlight">\(Q\)</span> is a matrix, we could just take its transpose to find the adoint.  However, with matrix-free methods, we need to implement the
adjoint-vector product directly.</p>
<p>The logic for the adjoint is that for a given <span class="math notranslate nohighlight">\(n = (n_1,\ldots, n_m, \ldots n_M)\)</span>, the <span class="math notranslate nohighlight">\(Q^T\)</span> product for that row has terms enter when</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(1 &lt; n_m \leq N\)</span>, entering into the identical <span class="math notranslate nohighlight">\(n\)</span> except with one less customer in the <span class="math notranslate nohighlight">\(m\)</span> position</p></li>
<li><p><span class="math notranslate nohighlight">\(1 \leq n_m &lt; N\)</span>, entering into the identical <span class="math notranslate nohighlight">\(n\)</span> except with one more customer in the <span class="math notranslate nohighlight">\(m\)</span> position</p></li>
</ol>
<p>Implementing this logic, first in math and then in code,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
    Q^T_{(n_1, \ldots, n_M)} \cdot \psi &amp;=
\theta \sum_{m=1}^M (n_m &gt; 1)  \psi(n_1, \ldots, n_m - 1, \ldots, n_M)\\
                                        &amp;+ \zeta \sum_{m=1}^M (n_m &lt; N)  \psi(n_1, \ldots, n_m + 1, \ldots, n_M)\\
                                        &amp;-\left(\theta\, \text{Count}(n_m &lt; N) + \zeta\, \text{Count}( n_m &gt; 1)\right)\psi(n_1, \ldots, n_M)
\end{align}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">Q_T_mul!</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="nd">@unpack</span> <span class="n">θ</span><span class="p">,</span> <span class="n">ζ</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">e_m</span> <span class="o">=</span> <span class="n">p</span>
    <span class="n">ψ</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">ψ</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="n">dψ</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>

    <span class="nd">@inbounds</span> <span class="k">for</span> <span class="n">ind</span> <span class="k">in</span> <span class="kt">CartesianIndices</span><span class="p">(</span><span class="n">ψ</span><span class="p">)</span>
        <span class="n">dψ</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">m</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">M</span>
            <span class="n">n_m</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">m</span><span class="p">]</span>
            <span class="k">if</span><span class="p">(</span><span class="n">n_m</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">dψ</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">+=</span> <span class="n">θ</span> <span class="o">*</span> <span class="n">ψ</span><span class="p">[</span><span class="n">ind</span> <span class="o">-</span> <span class="n">e_m</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
            <span class="k">end</span>
            <span class="k">if</span><span class="p">(</span><span class="n">n_m</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span>
                <span class="n">dψ</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ζ</span> <span class="o">*</span><span class="n">ψ</span><span class="p">[</span><span class="n">ind</span> <span class="o">+</span> <span class="n">e_m</span><span class="p">[</span><span class="n">m</span><span class="p">]]</span>
            <span class="k">end</span>
        <span class="k">end</span>
        <span class="n">dψ</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">θ</span> <span class="o">*</span> <span class="n">count</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span> <span class="o">.&lt;</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">ζ</span> <span class="o">*</span> <span class="n">count</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">I</span> <span class="o">.&gt;</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">ψ</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
    <span class="k">end</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Q_T_mul! (generic function with 1 method)
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">sparse</span></code> function for the operator is useful for testing that the function is correct, and is the adjoint of
our <code class="docutils literal notranslate"><span class="pre">Q</span></code> operator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c"># sparse is too slow for the full matrix</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">df</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_mul!</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="n">Q_T</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_T_mul!</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">sparse</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">-</span> <span class="n">sparse</span><span class="p">(</span><span class="n">Q_T</span><span class="p">));</span>  <span class="c"># reminder: use sparse only for testing!</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm((sparse(Q))&#39; - sparse(Q_T)) = 0.0
</pre></div>
</div>
</div>
</div>
<p>As discussed previously, the steady state can be found as the eigenvector associated with the zero eigenvalue (i.e., the one that solves <span class="math notranslate nohighlight">\(Q^T \psi = 0 \psi\)</span>).  We could
do this with a dense eigenvalue solution for relatively small matrices</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">eig_Q_T</span> <span class="o">=</span> <span class="n">eigen</span><span class="p">(</span><span class="kt">Matrix</span><span class="p">(</span><span class="n">Q_T</span><span class="p">))</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">real</span><span class="p">(</span><span class="n">eig_Q_T</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="k">end</span><span class="p">])</span>
<span class="n">direct_ψ</span> <span class="o">=</span> <span class="n">vec</span> <span class="o">./</span> <span class="n">sum</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">eig_Q_T</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="k">end</span><span class="p">];</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>eig_Q_T.values[end] = 1.1102230246251565e-15 + 0.0im
</pre></div>
</div>
</div>
</div>
<p>This approach relies on a full factorization of the underlying matrix, delivering the entire spectrum.  For our purposes, this is not necessary.</p>
<p>Instead, we could use the <code class="docutils literal notranslate"><span class="pre">Arpack.jl</span></code> package to target the eigenvalue of smallest absolute value, which relies on an iterative method.</p>
<p>A final approach in this case is to notice that the <span class="math notranslate nohighlight">\(\mathbf{N}\times\mathbf{N}\)</span> matrix is of
rank <span class="math notranslate nohighlight">\(\mathbf{N} - 1\)</span> when the Markov chain is irreducible.  The stationary solution is a vector in the <span class="math notranslate nohighlight">\(1\)</span>-dimensional nullspace
of the matrix.</p>
<p>Using Krylov methods to solve a linear system with the right-hand side all 0 values will converge to a point in the nullspace.  That is, <span class="math notranslate nohighlight">\(\min_x ||A x - 0||_2\)</span> solved
iteratively from a non-zero initial condition will converge to a point in the nullspace.</p>
<p>We can use various Krylov methods for this trick (e.g., if the matrix is symmetric and positive definite, we could use Conjugate Gradient) but in our case we will
use GMRES since we do not have any structure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c"># sparse is too slow for the full matrix</span>
<span class="n">Q_T</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_T_mul!</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="n">ψ</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">)</span> <span class="c"># can&#39;t use 0 as initial guess</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">ψ</span><span class="p">,</span> <span class="n">Q_T</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">))</span>  <span class="c"># i.e., solve Ax = 0 iteratively</span>
<span class="n">ψ</span> <span class="o">=</span> <span class="n">ψ</span> <span class="o">/</span> <span class="n">sum</span><span class="p">(</span><span class="n">ψ</span><span class="p">)</span>
<span class="nd">@show</span> <span class="n">norm</span><span class="p">(</span><span class="n">ψ</span> <span class="o">-</span> <span class="n">direct_ψ</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm(ψ - direct_ψ) = 6.098218047075983e-11
</pre></div>
</div>
</div>
</div>
<p>The speed and memory differences between these methods can be orders of magnitude.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c"># Dense and sparse matrices are too slow for the full dataset.</span>
<span class="n">Q_T</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_T_mul!</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
<span class="n">Q_T_dense</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">(</span><span class="n">Q_T</span><span class="p">)</span>
<span class="n">Q_T_sparse</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">(</span><span class="n">Q_T</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">eigen</span><span class="p">(</span><span class="o">$</span><span class="n">Q_T_dense</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">eigs</span><span class="p">(</span><span class="o">$</span><span class="n">Q_T_sparse</span><span class="p">,</span> <span class="n">nev</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="ss">:SM</span><span class="p">,</span> <span class="n">v0</span> <span class="o">=</span> <span class="n">iv</span><span class="p">)</span> <span class="n">setup</span> <span class="o">=</span> <span class="p">(</span><span class="n">iv</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">))</span>
<span class="nd">@btime</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">iv</span><span class="p">,</span> <span class="o">$</span><span class="n">Q_T</span><span class="p">,</span> <span class="o">$</span><span class="n">b</span><span class="p">)</span> <span class="n">setup</span> <span class="o">=</span> <span class="p">(</span><span class="n">iv</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  28.947 ms (21 allocations: 2.27 MiB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2.426 ms (370 allocations: 1.21 MiB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  179.302 μs (57 allocations: 51.00 KiB)
</pre></div>
</div>
</div>
</div>
<p>The differences become even more stark as the matrix grows.  With <code class="docutils literal notranslate"><span class="pre">default_params(N=5,</span> <span class="pre">M=5)</span></code>, the <code class="docutils literal notranslate"><span class="pre">gmres</span></code> solution is at least 3 orders of magnitude faster, and uses close to 3 orders of magnitude less memory than the dense solver.  In addition, the <code class="docutils literal notranslate"><span class="pre">gmres</span></code> solution is about an order of magnitude faster than the iterative sparse eigenvalue solver.</p>
<p>The algorithm can solve for the steady state of <span class="math notranslate nohighlight">\(10^5\)</span> states in a few seconds</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">stationary_ψ</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">Q_T</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="p">((</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_T_mul!</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="nb">true</span><span class="p">)</span>
    <span class="n">ψ</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">)</span> <span class="c"># can&#39;t use 0 as initial guess</span>
    <span class="n">sol</span> <span class="o">=</span> <span class="n">gmres!</span><span class="p">(</span><span class="n">ψ</span><span class="p">,</span> <span class="n">Q_T</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">N</span><span class="o">^</span><span class="n">p</span><span class="o">.</span><span class="n">M</span><span class="p">))</span>  <span class="c"># i.e., solve Ax = 0 iteratively</span>
    <span class="k">return</span> <span class="n">ψ</span> <span class="o">/</span> <span class="n">sum</span><span class="p">(</span><span class="n">ψ</span><span class="p">)</span>
<span class="k">end</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nd">@btime</span> <span class="n">stationary_ψ</span><span class="p">(</span><span class="o">$</span><span class="n">p</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1.358 s (90 allocations: 19.09 MiB)
</pre></div>
</div>
</div>
</div>
<p>As a final demonstration, consider calculating the full evolution of the <span class="math notranslate nohighlight">\(ψ(t)\)</span> Markov chain.  For the constant
<span class="math notranslate nohighlight">\(Q'\)</span> matrix, the solution to this system of equations is <span class="math notranslate nohighlight">\(\psi(t) = \exp(Q') \psi(0)\)</span></p>
<p>Matrix-free Krylov methods using a technique called <a class="reference external" href="https://en.wikipedia.org/wiki/Exponential_integrator">exponential integration</a> can solve this for high-dimensional problems.</p>
<p>For this, we can set up a <code class="docutils literal notranslate"><span class="pre">MatrixFreeOperator</span></code> for our <code class="docutils literal notranslate"><span class="pre">Q_T_mul!</span></code> function (equivalent to the <code class="docutils literal notranslate"><span class="pre">LinearMap</span></code>, but with some additional requirements for the ODE solver) and use the <a class="reference external" href="http://docs.juliadiffeq.org/latest/solvers/ode_solve.html#Exponential-Methods-for-Linear-and-Affine-Problems-1">LinearExponential</a> time-stepping method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">OrdinaryDiffEq</span><span class="p">,</span> <span class="n">DiffEqOperators</span>

<span class="k">function</span> <span class="n">solve_transition_dynamics</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="nd">@unpack</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">p</span>

    <span class="n">ψ_0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">;</span> <span class="n">fill</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">N</span><span class="o">^</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">O!</span> <span class="o">=</span> <span class="n">MatrixFreeOperator</span><span class="p">((</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Q_T_mul!</span><span class="p">(</span><span class="n">dψ</span><span class="p">,</span> <span class="n">ψ</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
                            <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="o">^</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="o">^</span><span class="n">M</span><span class="p">),</span> <span class="n">opnorm</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">-&gt;</span><span class="mf">1.25</span><span class="p">)</span>

    <span class="c"># define the corresponding ODE problem</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">ODEProblem</span><span class="p">(</span><span class="n">O!</span><span class="p">,</span><span class="n">ψ_0</span><span class="p">,(</span><span class="mf">0.0</span><span class="p">,</span><span class="n">t</span><span class="p">[</span><span class="k">end</span><span class="p">]),</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">solve</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">LinearExponential</span><span class="p">(</span><span class="n">krylov</span><span class="o">=</span><span class="ss">:simple</span><span class="p">),</span> <span class="n">tstops</span> <span class="o">=</span> <span class="n">t</span><span class="p">)</span>
<span class="k">end</span>
<span class="n">t</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">:</span><span class="mf">5.0</span><span class="o">:</span><span class="mf">100.0</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">default_params</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">solve_transition_dynamics</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">solve_bellman</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="p">[</span><span class="n">dot</span><span class="p">(</span><span class="n">sol</span><span class="p">(</span><span class="n">tval</span><span class="p">),</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">tval</span> <span class="k">in</span> <span class="n">t</span><span class="p">],</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s">&quot;t&quot;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;E_t(v)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/iterative_methods_sparsity_129_0.svg" src="../_images/iterative_methods_sparsity_129_0.svg" /></div>
</div>
<p>The above plot (1) calculates the full dynamics of the Markov chain from the <span class="math notranslate nohighlight">\(n_m = 1\)</span> for all <span class="math notranslate nohighlight">\(m\)</span> initial condition; (2) solves the dynamics of a system of a million ODEs; and (3) uses the calculation of the Bellman equation to find the expected valuation during that transition.  The entire process takes less than 30 seconds.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.6"
        },
        kernelOptions: {
            kernelName: "julia-1.6",
            path: "./tools_and_techniques"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.6'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="sidebar bd-sidebar inactive" id="site-navigation">

                <div class="sidebar__header">


                    Contents

                </div>

                <nav class="sidebar__nav" id="sidebar-nav" aria-label="Main navigation">
                    <p class="caption">
 <span class="caption-text">
  Getting Started with Julia
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/getting_started.html">
   1. Setting up Your Julia Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/julia_by_example.html">
   2. Introductory Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/julia_essentials.html">
   3. Julia Essentials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/fundamental_types.html">
   4. Arrays, Tuples, Ranges, and Other Fundamental Types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started_julia/introduction_to_types.html">
   5. Introduction to Types and Generic Programming
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Package Ecosystem
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/generic_programming.html">
   6. Generic Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/general_packages.html">
   7. General Purpose Packages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/data_statistical_packages.html">
   8. Data and Statistics Packages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../more_julia/optimization_solver_packages.html">
   9. Solvers, Optimizers, and Automatic Differentiation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Software Engineering
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../software_engineering/tools_editors.html">
   10. Visual Studio Code and Other Tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../software_engineering/version_control.html">
   11. GitHub, Version Control and Collaboration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../software_engineering/testing.html">
   12. Packages, Testing, and Continuous Integration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../software_engineering/need_for_speed.html">
   13. The Need for Speed
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="geom_series.html">
   14. Geometric Series for Elementary Economics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_algebra.html">
   15. Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="orth_proj.html">
   16. Orthogonal Projections and Their Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lln_clt.html">
   17. LLN and CLT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html">
   18. Linear State Space Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="finite_markov.html">
   19. Finite Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="stationary_densities.html">
   20. Continuous State Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kalman.html">
   21. A First Look at the Kalman Filter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="numerical_linear_algebra.html">
   22. Numerical Linear Algebra and Factorizations
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   23. Krylov Methods and Matrix Conditioning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamic Programming
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/short_path.html">
   24. Shortest Paths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/mccall_model.html">
   25. Job Search I: The McCall Search Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/mccall_model_with_separation.html">
   26. Job Search II: Search and Separation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/wald_friedman.html">
   27. A Problem that Stumped Milton Friedman
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/odu.html">
   28. Job Search III: Search with Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/career.html">
   29. Job Search IV: Modeling Career Choice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/jv.html">
   30. Job Search V: On-the-Job Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/optgrowth.html">
   31. Optimal Growth I: The Stochastic Optimal Growth Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/coleman_policy_iter.html">
   32. Optimal Growth II: Time Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/egm_policy_iter.html">
   33. Optimal Growth III: The Endogenous Grid Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/lqcontrol.html">
   34. LQ Dynamic Programming Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/perm_income.html">
   35. Optimal Savings I: The Permanent Income Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/perm_income_cons.html">
   36. Optimal Savings II: LQ Techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/smoothing.html">
   37. Consumption and Tax Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/ifp.html">
   38. Optimal Savings III: Occasionally Binding Constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/robustness.html">
   39. Robustness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/discrete_dp.html">
   40. Discrete State Dynamic Programming
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Modeling in Continuous Time
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../continuous_time/seir_model.html">
   41. Modeling COVID 19 with Differential Equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../continuous_time/covid_sde.html">
   42. Modeling Shocks in COVID 19 with Stochastic Differential Equations
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/schelling.html">
   43. Schelling’s Segregation Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/lake_model.html">
   44. A Lake Model of Employment and Unemployment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/rational_expectations.html">
   45. Rational Expectations Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/markov_perf.html">
   46. Markov Perfect Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/markov_asset.html">
   47. Asset Pricing I: Finite State Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/lucas_model.html">
   48. Asset Pricing II: The Lucas Asset Pricing Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/harrison_kreps.html">
   49. Asset Pricing III:  Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/uncertainty_traps.html">
   50. Uncertainty Traps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/aiyagari.html">
   51. The Aiyagari Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/arellano.html">
   52. Default Risk and Income Fluctuations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multi_agent_models/matsuyama.html">
   53. Globalization and Cycles
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Time Series Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series_models/arma.html">
   54. Covariance Stationary Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series_models/estspec.html">
   55. Estimation of Spectra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series_models/additive_functionals.html">
   56. Additive Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series_models/multiplicative_functionals.html">
   57. Multiplicative Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series_models/lu_tricks.html">
   58. Classical Control with Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series_models/classical_filtering.html">
   59. Classical Filtering With Linear Algebra
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamic Programming Squared
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/dyn_stack.html">
   60. Dynamic Stackelberg Problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/lqramsey.html">
   61. Optimal Taxation in an LQ Economy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/opt_tax_recur.html">
   62. Optimal Taxation with State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming_squared/amss.html">
   63. Optimal Taxation without State-Contingent Debt
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../about_lectures.html">
   64. About these Lectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../troubleshooting.html">
   65. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../zreferences.html">
   66. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../status.html">
   67. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="toolbar">

            <div class="toolbar__inner">

                <ul class="toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="../intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                    <!-- <li class="btn__search">
                        <form action="../search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off">
                            <i data-feather="search"></i>
                        </form>
                    </li> -->
                </ul>

                <ul class="toolbar__links">
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="_notebooks/tools_and_techniques/iterative_methods_sparsity.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li data-tippy-content="Download PDF" onClick="window.print()"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-julia.myst/tree/main/lectures/tools_and_techniques/iterative_methods_sparsity.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://mybinder.org/v2/gh/QuantEcon/lecture-julia.notebooks/main?urlpath=tree/tools_and_techniques/iterative_methods_sparsity.ipynb">BinderHub</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-julia.notebooks" data-urlpath="tree/lecture-julia.notebooks/tools_and_techniques/iterative_methods_sparsity.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://mybinder.org/v2/gh/QuantEcon/lecture-julia.notebooks/main?urlpath=tree/tools_and_techniques/iterative_methods_sparsity.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "tools_and_techniques/iterative_methods_sparsity";
                const repoURL = "https://github.com/QuantEcon/lecture-julia.notebooks";
                const urlPath = "tree/lecture-julia.notebooks/tools_and_techniques/iterative_methods_sparsity.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-54984338-8', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>